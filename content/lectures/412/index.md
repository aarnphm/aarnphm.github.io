---
id: index
tags:
  - seed
  - ml
  - linalg
description: linear algebra in transformers
date: "2025-09-26"
modified: 2025-09-26 02:14:19 GMT-04:00
title: 0[dot]412
---

slides: [[lectures/412/infer-0.412.pdf]]

## orientation

- anchor text: [[lectures/412/notes]] expands every derivation and links tools.
- prerequisites: [[lectures/411/notes#linear equation]] for row/column space intuition and [[lectures/2/attention first principle]] for attention basics.
- deliverables: reproduce the decoder block factorization, run the latent cache experiment, document MoE routing statistics, and consult [[lectures/412/deep research]] for extended proofs.
