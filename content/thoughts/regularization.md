---
id: regularization
tags:
  - ml
date: "2024-12-14"
modified: 2024-12-14 07:07:41 GMT-05:00
title: regularization
---

usually prone to overfitting given they are often over-parameterized

1. We can usually add regularization terms to the objective functions
2. Early stopping
3. Adding noise
4. structural regularization, via adding dropout

## dropout

a case of _structural regularization_

a technique of randomly drop each node with probability $p$
