---
date: "2026-01-28"
description: what-it's-like-ness, the hard problem, and why functional explanation keeps missing the target
id: phenomenal-consciousness
modified: 2026-01-28 02:30:00 GMT-05:00
seealso:
  - "[[thoughts/access consciousness]]"
  - "[[thoughts/dualism]]"
  - "[[thoughts/qualia]]"
  - "[[thoughts/philosophical zombies]]"
  - "[[thoughts/functionalism]]"
  - "[[thoughts/physicalism]]"
tags:
  - philosophy
  - consciousness
title: phenomenal consciousness
socials:
  sep: https://plato.stanford.edu/entries/consciousness/
  wikipedia: https://en.wikipedia.org/wiki/Phenomenal_consciousness
---

_photons strike retina, neurons fire in patterns we can map, and yet something else is happening: a felt quality, a what-it's-like-ness._

when i try to point at phenomenal consciousness, i'm pointing at that felt quality. the redness when i see red. the painfulness of pain. not the information processing, not the behavioral outputs, but the experiencing itself.

## what i'm pointing at

phenomenal consciousness: the qualitative, subjective character of mental states. nagel's (1974) formulation is still the clearest: there is something it is like to be in a conscious state. when you see red, taste coffee, feel pain, there's a felt quality. [@nagel1974bat]

useful terms: [[thoughts/qualia]] (the intrinsic feel itself), "what-it-is-like-ness" (nagel's locution), first-person character (the point-of-view structure). kriegel splits this into qualitative (WHAT appears) and subjective (THAT it appears for someone).

## how it differs from access consciousness

block (1995) drew the line: [@block1995confusion]

**phenomenal consciousness (p-consciousness)**: the felt quality. what red looks like, what pain feels like.

**[[thoughts/access consciousness]] (a-consciousness)**: information available for reasoning, report, behavioral control.

these can dissociate. block argues experience overflows access (sperling experiments: you see all the letters but can only report ~4). blindsight suggests the opposite: information guides action without experience, though whether this is genuine dissociation or degraded vision remains contested.

## the hard problem

chalmers (1995) split this cleanly: [@chalmers1995facingup]

easy problems are those amenable to functional explanation: discrimination, integration, reportability, attention, control. they are "easy" because we know what kind of answer would work: specify mechanisms that perform the functions.

the hard problem: why does any of this processing feel like anything at all. even with complete functional and structural knowledge—every circuit, every weight, every activation—there's an additional question: why is there something it's like to be that system.

levine (1983) calls this the explanatory gap: even true identity statements (pain = c-fiber firing) leave a gap. we can't see why that physical process produces that phenomenal quality. levine thinks this might be epistemic rather than metaphysical. [@levine1983gap]

## thought experiments

### mary's room

jackson (1982, 1986): mary knows all physical facts about color vision but has lived in a black-and-white room. when she leaves and sees red for the first time, does she learn something new. [@jackson1982epiphenomenalqualia]

if yes: there are facts about experience not captured by physical facts. [[thoughts/physicalism]] is false.

responses:

- **ability hypothesis** (lewis, nemirow): mary gains new abilities (recognizing, imagining red), not new propositional knowledge
- **acquaintance hypothesis** (conee): mary gains acquaintance with redness, a third kind of knowledge
- **old fact, new way** (horgan): she knew the fact but now knows it under a phenomenal concept

jackson himself later recanted epiphenomenalism but the argument remains canonical.

### what is it like to be a bat

nagel (1974): bats use echolocation, a sensory modality we lack. there's presumably something it's like for a bat to echolocate, but we cannot know what that's like from outside. the subjective character of experience is tied to a particular point of view, making it inaccessible to objective, third-person scientific investigation. [@nagel1974bat]

"every subjective phenomenon is essentially connected with a single point of view, and it seems inevitable that an objective, physical theory will abandon that point of view."

### [[thoughts/philosophical zombies]]

chalmers (1996): conceive of a being physically identical to you, functionally identical, but with no phenomenal consciousness. total darkness inside. [@chalmers1996consciousmind]

the conceivability argument:

1. zombies are conceivable (cannot be ruled out a priori)
2. whatever is conceivable is possible
3. therefore zombies are possible
4. if zombies are possible, consciousness is non-physical

surveys split on whether zombies are conceivable or possible, which is part of why the argument persists.

### inverted spectrum

shoemaker (1982), block (1990): two people functionally identical, same behavioral dispositions, same discriminations, but their qualitative experiences are inverted. where you see red, i experience what you'd call green. [@shoemaker1982invertedspectrum]

if possible: qualitative content isn't determined by functional role. [[thoughts/functionalism]] about [[thoughts/qualia]] fails. the quale itself is something over and above the functional organization.

## theories that try to explain it

### higher-order theories

rosenthal: a mental state is conscious iff it's the target of a higher-order thought (HOT) or perception. you're conscious of seeing red bc you have a (usually non-conscious) thought THAT you're seeing red.

pros: explains why we can have unconscious perceptions. fits with prefrontal involvement in consciousness.

problems: what about first-order states with no HOT. if HOT misrepresents, what determines phenomenal character.

### global workspace theory

baars (1988), dehaene: cognitive architecture where specialized processors compete for access to a global workspace. information in workspace gets broadcast widely across cortex. this broadcasting constitutes consciousness.

critique: GWT explains [[thoughts/access consciousness]] well. critics (block, chalmers) argue it doesn't address why broadcasting produces felt experience. it's a theory of access, not phenomenality. [@dehaene2011experimental]

### integrated information theory

tononi (2004, IIT 4.0 2023): starts from phenomenological axioms about experience. consciousness = integrated information (Φ). consciousness is identical to a maximally irreducible conceptual structure. [@tononi2023iit4]

distinctive claims:

- panpsychist implications: any system with Φ > 0 has some consciousness
- consciousness is substrate-independent but requires actual physical integration, not mere functional simulation

major criticisms:

- aaronson: IIT implies grid of inactive logic gates can be "unboundedly more conscious" than humans
- Φ is computationally intractable to calculate for realistic systems

### representationalism

dretske (1995), tye (1995): phenomenal character reduces to representational content. what it's like to see red = representing redness. experience is transparent: introspection reveals only represented objects/properties, not intrinsic features of experience itself. [@tye1995ten]

strong representationalism (tye, dretske): representation of the right kind is sufficient for [[thoughts/qualia]].

problem: inverted spectrum cases. if two people have same representational content but different [[thoughts/qualia]], representationalism fails.

## why functional explanations seem insufficient

the tension sits right here: functional explanations give me structure, dynamics, causal roles, input-output mappings. phenomenal properties feel like intrinsic features of experiences, not relations.

conceivability arguments lean on this gap. i can conceive systems with identical functions but different (or absent) [[thoughts/qualia]]. if that's genuinely conceivable, then phenomenal properties aren't fixed by functional properties.

chalmers' version: consciousness isn't logically supervenient on physical/functional facts. even with all the functional truths, phenomenal truths remain underdetermined. you can't deduce what red looks like from any functional description, no matter how complete.

## for AI systems (where the epistemic problem gets worse)

phenomenal consciousness hits a wall with artificial systems:

**the other minds problem, amplified**: we infer human consciousness through analogy (similar behavior, similar biology, shared evolutionary history). these anchors dissolve with artificial systems. different substrate, different architecture, no shared lineage.

**behavioral indistinguishability doesn't settle it**: a system could pass every behavioral test while having no phenomenal experience ([[thoughts/philosophical zombies|functional zombie]]). or it could fail tests while experiencing something we can't recognize.

**no access from outside**: phenomenal consciousness is first-personal by construction. third-person observation gives us behavior and functional properties. whether there's something it's like to be the system isn't empirically decidable from outside.

the deeper problem: we don't have a validated theory of consciousness. without knowing what consciousness IS (mechanistically, functionally, structurally), we can't tell which systems have it.

## key references

- nagel, thomas (1974). "what is it like to be a bat" _philosophical review_ 83(4): 435-450
- jackson, frank (1982). "epiphenomenal qualia" _philosophical quarterly_ 32(127): 127-136
- levine, joseph (1983). "materialism and qualia: the explanatory gap" _pacific philosophical quarterly_ 64(4): 354-361
- block, ned (1995). "on a confusion about a function of consciousness" _BBS_ 18(2): 227-247
- chalmers, david (1995). "facing up to the problem of consciousness" _JCS_ 2(3): 200-219
- chalmers, david (1996). _the conscious mind_
- tye, michael (1995). _ten problems of consciousness_
- dehaene, stanislas & changeux, jean-pierre (2011). "experimental and theoretical approaches to conscious processing" _neuron_ 70(2): 200-227
- tononi, giulio et al. (2023). "IIT 4.0" _PLOS computational biology_
