---
date: "2024-01-08"
description: and compression of human knowledge
id: large models
modified: 2025-10-29 02:15:48 GMT-04:00
tags:
  - ml
title: Foundational models
---

Popularized through [[thoughts/LLMs]], GPT-3 paper [@brown2020languagemodelsfewshotlearners]

Though, it should be thought as [[thoughts/Intelligence amplification]] rather than "artificial intelligence" system.

## Scaling laws

Initial [work](https://arxiv.org/abs/2001.08361) from OpenAI

Distributed serving of large models requires cost-efficient methods[^1]

- [Petals](https://petals.dev/): a decentralized system that run Llama 2 over internet

### large world models

[LWM](https://github.com/LargeWorldModel/LWM): implementation of [[thoughts/Attention#RingAttention|RingAttention]]

## visions

[^1]: https://arxiv.org/abs/2312.08361
