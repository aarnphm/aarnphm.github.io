---
date: "2026-01-28"
description: notes on property dualism, the hard problem, and why physicalism keeps failing
id: dualism
modified: 2026-01-28 01:56:38 GMT-05:00
seealso:
  - "[[thoughts/qualia]]"
  - "[[thoughts/philosophical zombies]]"
  - "[[thoughts/panpsychism]]"
  - "[[thoughts/access consciousness]]"
  - "[[thoughts/phenomenal consciousness]]"
  - "[[thoughts/functionalism]]"
  - "[[thoughts/physicalism]]"
tags:
  - philosophy
  - consciousness
title: dualism and philosophy of mind
---

## the mill argument

leibniz, 1714. suppose you could walk through a thinking machine, enlarged to the size of a mill. you'd find gears pushing gears, levers pulling levers. you wouldn't find perception. you wouldn't find the feeling of anything.

the argument: no matter how detailed the mechanical description, something is left out—the _experience_ itself. three centuries later we have transformer attention heads instead of gears, but the structure remains. we can trace information flow through circuits, identify features in activation space, boost specific directions and watch behavior change. we can see the machinery. the mill stays dark inside.

## access vs phenomenal consciousness

Ned Block's distinction:

- **access consciousness**: information globally available for reasoning, reporting, behavior. the stuff we can map with interpretability tools. the "easy" problem.
- **phenomenal consciousness**: the redness-of-red, the what-it's-like-ness. the feeling itself.

we keep building finer maps of access while phenomenal consciousness stays off-camera. the conflation of the two leads to cognitive science that explains everything _except_ experience.

## the hard problem

david chalmers' formulation: even given complete knowledge of the physical facts—every circuit, every weight, every activation pattern—we still cannot deduce _what it's like_ to be the system experiencing those states. the explanation of consciousness requires something beyond the physical facts.

this produces **property dualism**: mental properties are not reducible to physical properties, even if they depend on physical substrates.

## philosophical zombies

chalmers' thought experiment: a physical duplicate of a human with identical behavior but no inner experience. conceivable? if yes, then physical facts don't entail phenomenal facts. physicalism is false.

implication for AI: we cannot tell from outside whether a model that discusses qualia, reports uncertainty, generates text about inner experience—actually experiences anything. the lights might be on with nobody home.

## epiphenomenalism

if consciousness has no causal effects—if it's "steam above the factory"—then looking at the machinery tells you nothing about the steam. interpretability-from-within fails because consciousness leaves no traces to interpret.

frank jackson's "epiphenomenal qualia" (1982): mary the color scientist knows every physical fact about red but has never seen it. when she sees a red apple, does she learn something new? if yes, physicalism is false. we are stuck in mary's black-and-white room.

## IIT and its failures

Integrated Information Theory (Tononi): consciousness requires integrated information (phi > 0). feedforward networks get phi = 0. clean.

scott aaronson's critique: constructed a grid of inactive logic gates with phi higher than a human brain. a lookup table that IIT says is more conscious than you. if the math attributes consciousness to a CD-ROM, the math is wrong.

## why property dualism persists

22% of philosophers (PhilPapers survey) because alternatives keep failing:

- **reductive physicalism**: cannot close the explanatory gap
- **eliminativism**: denies the one thing we know for certain (that we're experiencing _something_)
- **panpsychism**: trades the emergence gap for a combination gap—if electrons have micro-experience, how do billions combine into your unified experience?

## the combination problem

william james (1890): if consciousness exists at the micro-level, how do micro-experiences combine into macro-experiences? panpsychism solves emergence but opens combination. still unresolved.

## what-we-know vs what-we-can-say

thomas nagel (1974): we can model bat-sonar computationally but cannot access what-echolocation-feels-like from the inside. third-person description cannot capture first-person phenomenology.

the same wall exists for models: we observe circuits, features, behavior. model-qualia (if any) remains opaque.

## the explanatory gap

joseph levine: even with complete physical knowledge, we cannot explain why particular physical states give rise to particular experiences. there is no imaginable mechanism that would close this gap.

## for AI systems

- we can map access-consciousness structures: circuits, features, information flow
- we cannot detect phenomenal consciousness: no test, no metric, no interpretability tool reaches it
- training increasingly capable systems while the gap stays open: mapping a coastline while insisting there's no ocean
- the stakes: building minds or building theater? we might never know

## key references

- chalmers, david. _the conscious mind_ (1996)
- block, ned. "on a confusion about a function of consciousness" (1995)
- jackson, frank. "epiphenomenal qualia" (1982)
- nagel, thomas. "what is it like to be a bat?" (1974)
- levine, joseph. "materialism and qualia: the explanatory gap" (1983)
- aaronson, scott. "why i am not an integrated information theorist" (2014)
- leibniz, g.w. _monadology_ (1714), section 17
- james, william. _the principles of psychology_ (1890)
