---
date: "2025-12-13"
description: and logical coherency
id: rationality
modified: 2025-12-14 19:11:26 GMT-05:00
seealso:
  - "[[thoughts/functionalism]]"
socials:
  jcarlsmith: https://joecarlsmith.com/category/rationality/
  lw: https://www.lesswrong.com/w/lesswrong-canon-on-rationality
tags:
  - pattern
  - philosophy
title: Rationality
---

Rationalist are mostly friends who read a lot #philosophy, but have a tendency to be STEM-focused. While they valorise extremes and often build towards social goods (which is good, _generally_), having a pragmatic view about the world will probably be more efficient use of time.

Tim Dettmers capture this in his argument against [AGI](https://timdettmers.com/2025/12/10/why-agi-will-not-happen/):

> A key problem with ideas, particularly those coming from the Bay Area, is that they often live entirely in the idea space. Most people who think about [[thoughts/AGI]], superintelligence, scaling laws, and hardware improvements treat these concepts as abstract ideas that can be discussed like philosophical thought experiments.
> In fact, a lot of the thinking about superintelligence and AGI comes from Oxford-style philosophy. Oxford, the birthplace of effective altruism, mixed with the rationality culture from the Bay Area, gave rise to a strong distortion of how to clearly think about certain ideas. All of this sits on one fundamental misunderstanding of AI and scaling: computation is physical.
