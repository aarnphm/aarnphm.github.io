---
id: "1"
tags:
  - seed
  - ml
description: and hollistic overview
date: "2025-08-28"
socials:
  link: https://tsfm.ca/lecture-one
modified: 2025-09-04 21:30:52 GMT-04:00
noindex: true
title: lecture one
---

See also: [[thoughts/tsfm/lecture-1-exercise]]

## Manifold Hypothesis

Markov (order-1, bigrams) versus uniform distributions

> As dimensionality grows, fractions of meaningful strings shrinks to zero (curse of dimensionality)

Structured data is more compressible; random data is near max entropy. (Entropy readout in text panel; RLE ratio in image panel.)

> [[/tags/ml|ML]]/DL uses data to fit the regularities of this structured slice; we approximate, we donâ€™t enumerate.

![[thoughts/gradient descent]]

![[thoughts/FFN#backpropagation]]
