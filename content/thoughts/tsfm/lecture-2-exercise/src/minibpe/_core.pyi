from __future__ import annotations

class Tokenizer:
    @staticmethod
    def train_from_files(paths: list[str], num_merges: int, num_threads: int | None = ..., pattern: str | None = ...) -> "Tokenizer": ...
    @staticmethod
    def train_from_texts(texts: list[str], num_merges: int, num_threads: int | None = ..., pattern: str | None = ...) -> "Tokenizer": ...
    @staticmethod
    def from_pretrained(dir: str, pattern: str | None = ...) -> "Tokenizer": ...
    def encode(self, text: str) -> list[int]: ...
    def decode(self, ids: list[int]) -> str: ...
    def merges_list(self) -> list[tuple[int, int, int]]: ...
    def vocab_pairs(self) -> list[tuple[list[int], int]]: ...
