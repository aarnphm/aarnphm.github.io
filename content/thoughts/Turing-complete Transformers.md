---
date: "2024-01-30"
description: well, here we go again.
id: Turing-complete Transformers
modified: 2025-12-24 18:21:52 GMT-05:00
tags:
  - pattern
  - ml
title: Turing-complete Transformers
---

https://twitter.com/burny_tech/status/1744100637187461455

The idea is to combine two small [[thoughts/Transformers|transformers]] rather than one [[thoughts/large models]]

More specialised on given tasks, and prove to be Turing-complete?

![[posts/images/shogoth-gpt.webp|Shogoth as GPTs]]

> Speculatively, people might think GPT-4 without any guardrails _could_ pass the Turing-test. A more important question is "What is the Turing-test equivalent for pseudo-intelligence system?"

John Searle famously said:

```quotes

Turing machine is not to be found in nature. They're to be found in our _interpretations_ of nature.

John Searle
```

the [paper](https://openreview.net/forum?id=MGWsPGogLH) detailed what is very similar to the setup of [recursive language model](https://alexzhang13.github.io/blog/2025/rlm/), ideally we want to deal with long-horizon tasks more effectively and economically viable.