---
date: "2025-11-10"
description: phenomenal properties and what resists functional explanation
id: qualia
modified: 2025-11-10 09:00:00 GMT-05:00
tags:
  - philosophy
  - pattern
  - consciousness
title: qualia
---

see also: [[thoughts/functionalism]], [[thoughts/identity]], [[thoughts/representations]]

The hard part isn't explaining what you do when you see red. It's explaining what red is _like_. The phenomenal character, the first-person givenness, the "what it's like" to have the experience—this is what resists functional analysis.

Thomas Nagel: "what is it like to be a bat?" [@nagel1974bat] The question isn't about bat behavior, bat neurology, bat information processing. It's about bat _experience_. If you can't access the first-person perspective, you haven't captured consciousness. And functional descriptions—input/output mappings, causal roles, computational states—never give you first-person perspective. They give you third-person structure.

## the explanatory gap

Chalmers distinguishes the easy problems from the hard problem. [@chalmers1996consciousmind] Easy problems: discrimination, integration, reportability, attention, wakefulness. These submit to functional explanation. You can specify causal roles, implement them, test them. Hard problem: why any of this feels like anything at all. Why there's subjective experience accompanying the information processing.

The gap isn't ignorance waiting to be filled. It's structural. Functional explanations tell you what systems _do_. Phenomenal properties are about what systems _feel_. The two don't connect—or so the argument goes.

> [!example] Mary's room
> Mary knows every physical and functional fact about color vision while living in a black-and-white room. When she leaves and sees red for the first time, she learns something new: what red is _like_. If functional/physical knowledge were complete, she'd have learned nothing. [@jackson1982epiphenomenalqualia; @jackson1986whatmary]

The knowledge argument (see [[thoughts/knowledge argument]]) makes this precise. No amount of third-person functional description captures first-person phenomenal character. The quale of red is additional to the functional role of red-processing.

## access vs phenomenal consciousness

Block's distinction: [@block1995confusion]

- **Access consciousness**: information poised for use in reasoning, report, action control. Functional through and through—defined by availability, integration, control.
- **Phenomenal consciousness**: what it's like, subjective character, qualia. Not obviously functional.

They can come apart. Blindsight patients have visual information (access) without visual experience (phenomenal). Tip-of-the-tongue states have phenomenal character without full access to content. The two track different things.

This matters for [[thoughts/functionalism]]. If mental states are functional roles, and phenomenal consciousness isn't functional, then either phenomenal consciousness isn't mental (implausible) or functionalism is incomplete.

## the functionalist response

Three strategies:

**1. deny the intuition.** Qualia don't exist as separate properties. "What it's like" talk is confused. All consciousness is access consciousness—phenomenal talk just picks out functional properties we haven't analyzed clearly yet. [@dennett1988quining]

Problem: seems to change the subject. When you ask about subjective experience and get told it's really just functional access, something's been left out.

**2. expand the functional role.** Include phenomenal properties in the role specification. Pain isn't just "state caused by damage that causes avoidance." It's "state with phenomenal character Q that's caused by damage and causes avoidance." [@levin2024functionalism]

Problem: this doesn't explain phenomenal character—it just adds it to the specification. You've labeled the mystery, not solved it. And it blocks multiple realization: if phenomenal character is part of the role, systems with different phenomenal character (inverted qualia—see [[thoughts/inverted spectrum]]) aren't realizing the same role.

**3. representationalism.** Phenomenal properties are representational properties. What it's like to see red = representing red. Representation is functional (information, tracking, control), so phenomenal properties reduce to functional properties after all. [@tye1995ten; @dretske1995naturalizing]

Problem: representation underdetermines phenomenology. Same representational content, different phenomenal character (inverted spectrum again). And some experiences (pains, moods, background feelings) don't obviously represent anything external.

## the modal arguments

The strongest pressure comes from conceivability arguments:

- [[thoughts/philosophical zombies]]: functional duplicates without consciousness are conceivable, maybe possible, maybe actual (in other possible worlds). If zombies are metaphysically possible, phenomenal properties are additional to functional properties.
- [[thoughts/inverted spectrum]]: same functional role, different phenomenal character (your red = my green). If this is possible, functional role doesn't determine qualia.
- [[thoughts/knowledge argument]]: knowing all functional facts doesn't give you phenomenal knowledge. Physical/functional facts leave phenomenal facts open.

All three arguments use the same strategy: show that phenomenal properties can vary independently of functional properties. If they can vary independently, they're not identical. Functional roles don't constitute phenomenal character.

## contemporary handles

**mechanistic interpretability and qualia.** When we decompose [[thoughts/LLMs]] into functional features via sparse autoencoders, we find causally individuated representations: direction X means "in French," direction Y means "talking about code." [@geiger2025causalabstraction] These are access properties—information available for downstream use. No pressure toward phenomenal properties.

Does the model have _what-it's-like_ to process French? Nothing in the functional decomposition tells you. The mechanistic story is complete without it. This is either evidence that qualia don't exist (functionalist conclusion) or evidence that functional analysis misses something (anti-functionalist conclusion).

The interpretability work doesn't settle the metaphysics. It just makes the question sharper: if we have complete functional understanding, complete causal decomposition, complete ability to predict and intervene—and still no phenomenal story—what are we missing? Or are we missing anything?

**embodied and enactive approaches.** Maybe the problem is treating qualia as intrinsic properties of brain states. Phenomenal character might be relational: how body-in-environment makes sense of perturbations, how organism maintains viability, how sensorimotor loops couple perception and action. [@thompson2007mind]

Redness isn't property of neurons or even neural-functional states. It's how visual system differentiates certain wavelengths for action-relevant purposes in ecological context. "What it's like" is _how it enables you to cope_. Functional role plus embodied context plus developmental history. Richer functional story, not escape from functionalism.

But does this capture first-person givenness? Or does it just add more third-person structure (embodiment, action, context) to the functional story? The enactivist says these aren't third-person when you're _living_ them—they're your engaged perspective. The critic says this still doesn't explain why engagement feels like anything.

## why it matters

The qualia problem isn't armchair speculation. It's live question for:

- **AI consciousness:** If we build systems that pass every functional test (report their states, behave appropriately, show attention dynamics), do they have phenomenal experience? Functional equivalence doesn't tell you. You need additional criteria—but what criteria, and why? [@chalmers1996consciousmind]

- **Clinical states:** Anesthesia, vegetative states, locked-in syndrome. What distinguishes unconscious functional processing from conscious functional processing? Access and report can fail while phenomenal experience continues (locked-in). They can be present while phenomenal experience is absent (general anesthesia, maybe). Clinical decisions require distinguishing these, but functional tests conflate them. [@block1995confusion]

- **Animal consciousness:** Which animals have phenomenal experience? Functional complexity (neural processing, behavioral flexibility) is measurable. Phenomenal consciousness isn't—unless you think it reduces to functional properties. The ethical stakes are high: suffering requires phenomenal consciousness, not just functional responses to damage.

- **Self-knowledge:** You have direct access to your phenomenal states but only indirect access to your functional states. You know what red looks like; you don't know how your visual system processes wavelengths. If mental states are functional roles, you don't know your own mind directly. Counterintuitive. Maybe self-knowledge is phenomenal knowledge, not functional knowledge.

The functionalist wants to explain mind in terms of causal structure—what things do, how they relate, what role they play. Qualia seem to be leftovers: properties that don't reduce to structure. Either they're illusions (eliminativism), or they're additional to functional story (dualism), or they're functional properties we haven't analyzed right yet (functionalism, optimistic). No consensus.

Wittgenstein's line: "The aspects of things that are most important for us are hidden because of their simplicity and familiarity." [@wittgenstein1953pi] Maybe qualia are too close, too immediate, too familiar to capture in functional terms. Or maybe the appearance of irreducibility is confusion—mistaking familiarity for metaphysical depth.

The debate continues. Which means the functionalist story about mind remains incomplete—or complete and missing nothing, depending who you ask.

---

see also: [[thoughts/philosophical zombies]], [[thoughts/knowledge argument]], [[thoughts/inverted spectrum]], [[thoughts/chinese room]], [[thoughts/Attention]]
