---
id: OpenLLM 0.6 releases notes
tags:
  - bentoml
date: "2024-07-10"
title: OpenLLM 0.6 releases notes
---

## 0.6

We are thrilled to announce the release of OpenLLM 0.6, which marks a significant shift in our project's philosophy. This release introduces breaking changes to the codebase, reflecting our renewed focus on streamlining cloud deployment for large language models (LLMs).

## simplicity and performance.

In the previous 0.5 release, our goal was to provide users with an easy-to-use and intuitive developer experience while maintaining full control over customization. However, we realized that the customization options in OpenLLM sometimes led to scope creep, deviating from our core focus on cloud deployment. With the rise of local LLM deployment and the growing emphasis on LLM-focused application development, we have decided to concentrate on what OpenLLM does best: cloud deployment

We have completely revamped the architecture to make OpenLLM a tool that simplifies running LLMs on the cloud, prioritizing ease of use and performance. This means that 0.6 breaks away from many of the old APIs provided in 0.5, reinventing itself as an easy-to-use CLI tool with cross-platform compatibility for users to deploy local LLMs to the cloud.

To learn more about the exciting features and capabilities of OpenLLM, visit our [GitHub](https://github.com/bentoml/OpenLLM) repository. We invite you to explore the new release, provide feedback, and join us in our mission to make cloud deployment of LLMs accessible and efficient for everyone.

Thank you for your continued support and trust in OpenLLM. We look forward to seeing the incredible applications you will build with this powerful tool.
