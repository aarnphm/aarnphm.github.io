---
id: research
tags:
  - fruit
description: and my interests
transclude:
  dynalist: false
  title: false
date: "2025-08-12"
modified: 2025-09-12 19:29:54 GMT-04:00
title: research
---

I would like to do research at some point. I'm interested in [[thoughts/mechanistic interpretability|emergent properties]] in [[/tags/ml|ML]] system.

> [!abstract]- For non-ML folks
>
> Whenever I introduce myself to new people, I often said that I work on ML infrastructure. Yet, people doesn't seem to understand
> what this means. I then have to follow up with: "Think of infrastructure that run ChatGPT."
>
> It dawns on me that ML infrastructure is still a relatively esoteric field despite its huge relevance in SF/academia literature.
> So here is a dialectic attempt to clarify what I do, in a Q&A format.
>
> **Q**: _So why do we need to do research in ML system?_
>
> **A**: Imagine you own a car that's already pretty fast--but you're not really content with "fast". You decide to mod the engine, strip away passenger sea
> add new pistons, reroute fuel lines, etc. What happens when the engine receive additional boost? What happens if you change the certain tyres grip level? What happens when you
> hardening/soften part of the suspension?
>
> If you think about it, every tasks in our life is an optimisation problem. We optimise our sleep schedule by not looking at blue lights, set temperature to ensure we hit a certain threshold for REM. So running ML models efficiently is not an outlier. Scaling intelligence is an engineering problem, and we will need reliable and efficient infrastructure to push the frontier of science and quality of life.
> [[thoughts/Transformers]] is efficient, in a sense we have figured out a way to map discrete information into continuous, multi-dimensional spaces that machine can interpolate upon. Yet, front tier labs still struggles to create large enough margins.
>
> **Q**:
