@article{mitchell1912backwardartofspendingmoney,
  title = {The Backward Art of Spending Money},
  author = {Wesley C. Mitchell},
  year = {1912},
  journal = {The American Economic Review},
  publisher = {American Economic Association},
  volume = {2},
  number = {2},
  pages = {269--281},
  issn = {00028282},
  url = {http://www.jstor.org/stable/1827579},
  urldate = {2024-11-27}
}

@article{10.1093/mind/LIX.236.433,
  title = {{i.—Computing Machinery And Intelligence}},
  author = {Turing, A. M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  eprint = {https://academic.oup.com/mind/article-pdf/LIX/236/433/30123314/lix-236-433.pdf},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  doi = {10.1093/mind/LIX.236.433},
  issn = {0026-4423},
  url = {https://doi.org/10.1093/mind/LIX.236.433}
}

@article{rosenblatt1958perceptron,
  title = {The perceptron: A probabilistic model for information storage and organization in the brain},
  author = {Rosenblatt, F.},
  year = {1958},
  journal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  doi = {10.1037/h0042519}
}

@article{friedman1970social,
  title = {The Social Responsibility of Business is to Increase its Profits},
  author = {Friedman, Milton},
  year = {1970},
  month = {September 13},
  journal = {The New York Times Magazine}
}

@article{Donaldson1984Corporation,
  title = {Corporations \& Morality},
  author = {Thomas Donaldson},
  year = {1984},
  journal = {No\^{u}s},
  publisher = {Wiley-Blackwell},
  volume = {18},
  number = {3},
  pages = {548--551},
  doi = {10.2307/2215231}
}

@article{ackley_learning_1985,
  title = {A Learning Algorithm for Boltzmann Machines},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  year = {1985},
  journal = {Cognitive Science},
  publisher = {Wiley Online Library},
  volume = {9},
  number = {1},
  pages = {147--169},
  doi = {10.1207/s15516709cog0901_7}
}

@article{Cybenko1989,
  title = {Approximation by superpositions of a sigmoidal function},
  author = {Cybenko, George},
  year = {1989},
  journal = {Mathematics of Control, Signals, and Systems},
  publisher = {Springer},
  volume = {2},
  number = {4},
  pages = {303--314}
}

@article{crenshaw1991mapping,
  title = {Mapping the Margins: Intersectionality, Identity Politics, and Violence against Women of Color},
  author = {Crenshaw, Kimberl{\'e}},
  year = {1991},
  journal = {Stanford Law Review},
  volume = {43},
  number = {6},
  pages = {1241--1299}
}

@article{Wolpert1997NoFreeLunch,
  title = {No free lunch theorems for optimization},
  author = {Wolpert, D.H. and Macready, W.G.},
  year = {1997},
  journal = {IEEE Transactions on Evolutionary Computation},
  volume = {1},
  number = {1},
  pages = {67--82},
  doi = {10.1109/4235.585893},
  keywords = {Iron;Evolutionary computation;Information theory;Minimax techniques;Simulated annealing;Algorithm design and analysis;Performance analysis;Probability distribution;Bayesian methods}
}

@article{hochreiter1997long,
  title = {Long Short-Term Memory},
  author = {Hochreiter, Sepp and Schmidhuber, J{"u}rgen},
  year = {1997},
  journal = {Neural Computation},
  publisher = {MIT Press},
  note = {Technical Report, Fakultät für Informatik, Technische Universität München}
}

@article{doi:10.1080/09515080050002726,
  title = {Content and cluster analysis: Assessing representational similarity in neural systems},
  author = {Aarre Laakso and Garrison Cottrell},
  year = {2000},
  journal = {Philosophical Psychology},
  eprint = {https://doi.org/10.1080/09515080050002726},
  publisher = {Routledge},
  volume = {13},
  number = {1},
  pages = {47--76},
  doi = {10.1080/09515080050002726},
  url = {https://doi.org/10.1080/09515080050002726}
}

@article{faraone2006age,
  title = {The age-dependent decline of attention deficit hyperactivity disorder: a meta-analysis of follow-up studies},
  author = {Faraone, Stephen V and Biederman, Joseph and Mick, Eric},
  year = {2006},
  journal = {Psychological medicine},
  publisher = {Cambridge University Press},
  volume = {36},
  number = {2},
  pages = {159--165}
}

@article{handler2008avoidanotheraiwinter,
  title = {Avoiding Another AI Winter},
  author = {Hendler, James},
  year = {2008},
  journal = {IEEE Intelligent Systems},
  volume = {23},
  number = {2},
  pages = {2--4},
  doi = {10.1109/MIS.2008.20},
  keywords = {Artificial intelligence;Europe;Educational institutions;Computer science;Consumer products;Medical services;Biomedical equipment;Web search;Data mining;Information filtering;artificial intelligence;AI Winter;computer science;expert systems;DARPA;Sixth Framework Programme;Seventh Framework Programme;Hai Zhuge}
}

@article{cavoukian2009privacy,
  title = {Privacy by Design: The 7 Foundational Principles},
  author = {Cavoukian, Ann},
  year = {2009},
  note = {Framework developed at the Information and Privacy Commissioner of Ontario, Canada},
  institution = {Information and Privacy Commissioner of Ontario}
}

@article{https://doi.org/10.1111/j.1468-2370.2009.00275.x,
  title = {The Business Case for Corporate Social Responsibility: A Review of Concepts, Research and Practice},
  author = {Carroll, Archie B. and Shabana, Kareem M.},
  year = {2010},
  journal = {International Journal of Management Reviews},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-2370.2009.00275.x},
  volume = {12},
  number = {1},
  pages = {85--105},
  doi = {https://doi.org/10.1111/j.1468-2370.2009.00275.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2370.2009.00275.x},
  abstract = {In this review, the primary subject is the ‘business case’ for corporate social responsibility (CSR). The business case refers to the underlying arguments or rationales supporting or documenting why the business community should accept and advance the CSR ‘cause’. The business case is concerned with the primary question: What do the business community and organizations get out of CSR? That is, how do they benefit tangibly from engaging in CSR policies, activities and practices? The business case refers to the bottom-line financial and other reasons for businesses pursuing CSR strategies and policies. In developing this business case, the paper first provides some historical background and perspective. In addition, it provides a brief discussion of the evolving understandings of CSR and some of the long-established, traditional arguments that have been made both for and against the idea of business assuming any responsibility to society beyond profit-seeking and maximizing its own financial well-being. Finally, the paper addresses the business case in more detail. The goal is to describe and summarize what the business case means and to review some of the concepts, research and practice that have come to characterize this developing idea.}
}

@article{vandekerckhove2012organize,
  title = {Can We Organize Courage? Implications from Foucault's Parrhesia},
  author = {Vandekerckhove, Wim and Langenberg, Suzan},
  year = {2012},
  journal = {Electronic Journal of Business Ethics and Organizational Studies},
  url = {https://ssrn.com/abstract=2005662}
}

@article{skirrow2013emotional,
  title = {Emotional lability, comorbidity and impairment in adults with attention-deficit hyperactivity disorder},
  author = {Skirrow, Caroline and Asherson, Philip},
  year = {2013},
  journal = {Journal of affective disorders},
  publisher = {Elsevier},
  volume = {147},
  number = {1-3},
  pages = {80--86}
}

@article{srivastava_dropout_2014,
  title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  year = {2014},
  journal = {Journal of Machine Learning Research},
  volume = {15},
  number = {56},
  pages = {1929--1958}
}

@article{raghupathi2014creating,
  title = {Creating value in health care through big data: opportunities and policy implications},
  author = {Raghupathi, Wullianallur and Raghupathi, Viju},
  year = {2014},
  journal = {Health Information Science and Systems},
  publisher = {BioMed Central},
  volume = {2},
  number = {1},
  pages = {3},
  doi = {10.1186/2047-2501-2-3}
}

@article{chang2014serious,
  title = {Serious transport accidents in adults with attention-deficit/hyperactivity disorder and the effect of medication: a population-based study},
  author = {Chang, Zheng and Lichtenstein, Paul and D’Onofrio, Brian M and Sj{\"o}lander, Arvid and Larsson, Henrik},
  year = {2014},
  journal = {JAMA psychiatry},
  publisher = {American Medical Association},
  volume = {71},
  number = {3},
  pages = {319--325}
}

@article{dalsgaard2014adhd,
  title = {ADHD, stimulant treatment in childhood and subsequent substance abuse in adulthood—a naturalistic long-term follow-up study},
  author = {Dalsgaard, S{\o}ren and Mortensen, Preben Bo and Frydenberg, Morten and Thomsen, Per Hove},
  year = {2014},
  journal = {Addictive behaviors},
  publisher = {Elsevier},
  volume = {39},
  number = {1},
  pages = {325--328}
}

@article{jordan2015machine,
  title = {Machine learning: Trends, perspectives, and prospects},
  author = {Jordan, Michael I and Mitchell, Tom M},
  year = {2015},
  journal = {Science},
  publisher = {American Association for the Advancement of Science},
  volume = {349},
  number = {6245},
  pages = {255--260}
}

@article{BBCGoogleApology2015,
  title = {Google apologises for Photos app's racist blunder},
  author = {{BBC News}},
  year = {2015},
  month = jul,
  journal = {BBC News},
  url = {https://www.bbc.com/news/technology-33347866},
  note = {Accessed on October 09, 2024}
}

@article{blair2015ofcorporations,
  title = {Of Corporations, Courts, Personhood, and Morality},
  author = {Margaret M. Blair},
  year = {2015},
  journal = {Business Ethics Quarterly},
  publisher = {Cambridge University Press},
  volume = {25},
  number = {4},
  pages = {415--431},
  issn = {1052150X},
  url = {http://www.jstor.org/stable/43973409},
  urldate = {2024-11-19},
  abstract = {Since the dawn of capitalism, corporations have been regarded by the law as separate legal "persons." Corporate "personhood" has nonetheless remained controversial, and our understanding of corporate personhood often influences our thinking about the social responsibilities of corporations. This essay, written in honor of Prof. Thomas Donaldson, explores the tension in recent decisions by the U.S. Supreme Court and the Delaware Chancery Court about what corporations are, whose interests they serve, and who gets to make decisions about what they do. These decisions suggest that the law does not unequivocally support Donaldson's vision of corporations as "moral" persons.}
}

@article{strine2015corporate,
  title = {Corporate Power Ratchet: The Courts' Role in Eroding 'We the People's' Ability to Constrain Our Corporate Creations},
  author = {Strine Jr, Leo E.},
  year = {2015},
  journal = {Harvard Civil Rights-Civil Liberties Law Review},
  volume = {51},
  pages = {423}
}

@article{polanczyk2015annual,
  title = {Annual research review: A meta-analysis of the worldwide prevalence of mental disorders in children and adolescents},
  author = {Polanczyk, Guilherme V and Salum, Giovanni A and Sugaya, Luisa S and Caye, Arthur and Rohde, Luis A},
  year = {2015},
  journal = {Journal of child psychology and psychiatry},
  publisher = {Wiley Online Library},
  volume = {56},
  number = {3},
  pages = {345--365}
}

@article{doi:10.1057/jit.2015.5,
  title = {Big other: Surveillance Capitalism and the Prospects of an Information Civilization},
  author = {Shoshana Zuboff},
  year = {2015},
  journal = {Journal of Information Technology},
  eprint = {https://doi.org/10.1057/jit.2015.5},
  volume = {30},
  number = {1},
  pages = {75--89},
  doi = {10.1057/jit.2015.5},
  url = {https://doi.org/10.1057/jit.2015.5},
  abstract = {This article describes an emergent logic of accumulation in the networked sphere, ‘surveillance capitalism,’ and considers its implications for ‘information civilization.’ The institutionalizing practices and operational assumptions of Google Inc. are the primary lens for this analysis as they are rendered in two recent articles authored by Google Chief Economist Hal Varian. Varian asserts four uses that follow from computer-mediated transactions: data extraction and analysis,’ ‘new contractual forms due to better monitoring,’ ‘personalization and customization, ’ and continuous experiments. ’ An examination of the nature and consequences of these uses sheds light on the implicit logic of surveillance capitalism and the global architecture of computer mediation upon which it depends. This architecture produces a distributed and largely uncontested new expression of power that I christen: Big Other. ’ It is constituted by unexpected and often illegible mechanisms of extraction, commodification, and control that effectively exile persons from their own behavior while producing new markets of behavioral prediction and modification. Surveillance capitalism challenges democratic norms and departs in key ways from the centuries-long evolution of market capitalism.}
}

@article{AngwinLarsonMattuKirchner2016,
  title = {How We Analyzed the {COMPAS} Recidivism Algorithm},
  author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  year = {2016},
  month = may,
  journal = {ProPublica},
  url = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
  note = {Accessed on October 09, 2024}
}

@article{10.1257/jel.54.2.442,
  title = {The Economics of Privacy},
  author = {Acquisti, Alessandro and Taylor, Curtis and Wagman, Liad},
  year = {2016},
  month = jun,
  journal = {Journal of Economic Literature},
  volume = {54},
  number = {2},
  pages = {442–92},
  doi = {10.1257/jel.54.2.442},
  url = {https://www.aeaweb.org/articles?id=10.1257/jel.54.2.442}
}

@article{obermeyer2016predicting,
  title = {Predicting the Future — Big Data, Machine Learning, and Clinical Medicine},
  author = {Obermeyer, Ziad and Emanuel, Ezekiel J.},
  year = {2016},
  journal = {New England Journal of Medicine},
  publisher = {Massachusetts Medical Society},
  volume = {375},
  number = {13},
  pages = {1216--1219},
  doi = {10.1056/NEJMp1606181},
  pmcid = {PMC5070532}
}

@article{lundberg2017unified,
  title = {A Unified Approach to Interpreting Model Predictions},
  author = {Lundberg, Scott M and Lee, Su-In},
  year = {2017},
  journal = {Advances in Neural Information Processing Systems},
  volume = {30},
  pages = {4765--4774}
}

@article{sibley2017defining,
  title = {Defining ADHD symptom persistence in adulthood: optimizing sensitivity and specificity},
  author = {Sibley, Margaret H and Swanson, James M and Arnold, L Eugene and Hechtman, Lily T and Owens, Elizabeth B and Stehli, Annamarie and Abikoff, Howard and Hinshaw, Stephen P and Molina, Brooke SG and Mitchell, John T and others},
  year = {2017},
  journal = {Journal of child psychology and psychiatry},
  publisher = {Wiley Online Library},
  volume = {58},
  number = {6},
  pages = {655--662}
}

@article{srnicek2017platformcapitalism,
  title = {The challenges of platform capitalism: Understanding the logic of a new business model},
  author = {Srnicek, Nick},
  year = {2017},
  journal = {Juncture},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/newe.12023},
  volume = {23},
  number = {4},
  pages = {254--257},
  doi = {https://doi.org/10.1111/newe.12023},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/newe.12023},
  abstract = {The platform business model is predicated upon a voracious appetite for data that can only be sated by disregard for privacy (and often workers' rights), and constant outward expansion. As they become ever more central to the global economy, Nick Srnicek argues that it's incumbent on us to understand how they function.}
}

@article{resnick2018cambridge,
  title = {Cambridge Analytica’s “psychographic microtargeting”: what’s bullshit and what’s legit},
  author = {Resnick, Brian},
  year = {2018},
  journal = {Vox},
  url = {https://www.vox.com/science-and-health/2018/3/23/17152564/cambridge-analytica-psychographic-microtargeting-what}
}

@article{8436400,
  title = {User Data Privacy: Facebook, Cambridge Analytica, and Privacy Protection},
  author = {Isaak, Jim and Hanna, Mina J.},
  year = {2018},
  month = aug,
  journal = {Computer},
  volume = {51},
  number = {8},
  pages = {56--59},
  doi = {10.1109/MC.2018.3191268},
  issn = {1558-0814},
  abstract = {With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
  keywords = {data privacy;Facebook;Cambridge Analytica;user data privacy;privacy protection;The Policy Corner;Internet/Web technologies;security;online security;data security;privacy;cybercrime;social media;PII;personally identifiable information}
}

@article{rajkomar2018ensuring,
  title = {Ensuring Fairness in Machine Learning to Advance Health Equity},
  author = {Rajkomar, Alvin and Hardt, Michaela and Howell, Michael D. and Corrado, Greg S. and Chin, Marshall H.},
  year = {2018},
  journal = {Annals of Internal Medicine},
  publisher = {American College of Physicians},
  volume = {169},
  number = {12},
  pages = {866--872},
  doi = {10.7326/M18-1990}
}

@article{doi:10.1126/sciadv.aao5580,
  title = {The accuracy, fairness, and limits of predicting recidivism},
  author = {Julia Dressel  and Hany Farid},
  year = {2018},
  journal = {Science Advances},
  eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.aao5580},
  volume = {4},
  number = {1},
  pages = {eaao5580},
  doi = {10.1126/sciadv.aao5580},
  url = {https://www.science.org/doi/abs/10.1126/sciadv.aao5580},
  abstract = {Should we trust computers to make life-altering decisions in the criminal justice system? Algorithms for predicting recidivism are commonly used to assess a criminal defendant’s likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS’s collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.}
}

@article{carr2019thieves,
  title = {Thieves of Experience: How Google and Facebook Corrupted Capitalism},
  author = {Carr, Nicholas},
  year = {2019},
  month = jan,
  day = {15},
  journal = {Los Angeles Review of Books},
  url = {https://lareviewofbooks.org/article/thieves-of-experience-how-google-and-facebook-corrupted-capitalism/},
  note = {Review of "The Age of Surveillance Capitalism" by Shoshana Zuboff}
}

@article{HaoKarBuolamwini2019,
  title = {Can you make {AI} fairer than a judge? {Play} our courtroom algorithm game},
  author = {Hao, Karen and Kar, Jonathan and Buolamwini, Joy},
  year = {2019},
  month = oct,
  journal = {MIT Technology Review},
  url = {https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/amp/},
  note = {Accessed on October 09, 2024}
}

@article{susser2019technology,
  title = {Technology, autonomy, and manipulation},
  author = {Susser, Daniel and Roessler, Beate and Nissenbaum, Helen},
  year = {2019},
  journal = {Internet Policy Review},
  volume = {8},
  number = {2},
  doi = {10.14763/2019.2.1410},
  url = {https://policyreview.info/articles/analysis/technology-autonomy-and-manipulation}
}

@article{radford2019language,
  title = {Language Models are Unsupervised Multitask Learners},
  author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year = {2019}
}

@article{obermeyer2019dissecting,
  title = {Dissecting racial bias in an algorithm used to manage the health of populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  journal = {Science},
  publisher = {American Association for the Advancement of Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  doi = {10.1126/science.aax2342}
}

@article{floridi2019unified,
  title = {A Unified Framework of Five Principles for AI in Society},
  author = {Floridi, Luciano},
  year = {2019},
  journal = {SSRN Electronic Journal},
  publisher = {SSRN},
  doi = {10.2139/ssrn.3831321}
}

@article{zafar2019dlime,
  title = {DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems},
  author = {Zafar, Muhammad Rehman and Khan, Naimul Mefraz},
  year = {2019},
  journal = {arXiv preprint arXiv:1906.10263}
}

@article{mitchell2019model,
  title = {Model Cards for Model Reporting},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  year = {2019},
  journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  publisher = {ACM},
  pages = {220--229}
}

@article{Wolraich2019,
  title = {Clinical Practice Guideline for the Diagnosis, Evaluation, and Treatment of Attention-Deficit/Hyperactivity Disorder in Children and Adolescents},
  author = {Mark L. Wolraich and Joseph F. Hagan Jr and Carla Allan and Eugenia Chan and Dale Davison and Marian Earls and Steven W. Evans and Susan K. Flinn and Tanya Froehlich and Jennifer Frost and Joseph R. Holbrook and Christoph U. Lehmann and Herschel R. Lessin and Kymika Okechukwu},
  year = {2019},
  month = oct,
  journal = {Pediatrics},
  volume = {144},
  number = {4},
  pages = {e20192528},
  doi = {10.1542/peds.2019-2528},
  url = {https://pubmed.ncbi.nlm.nih.gov/31570648/}
}

@article{rudin2019stop,
  title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  author = {Rudin, Cynthia},
  year = {2019},
  journal = {Nature Machine Intelligence},
  eprint = {1811.10154},
  publisher = {Nature Publishing Group},
  volume = {1},
  number = {5},
  pages = {206--215},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML}
}

@article{zhang2020labelingmethod,
  title = {A Labeling Method for Financial Time Series Prediction Based on Trends},
  author = {Wu, Dingming and Wang, Xiaolong and Su, Jingyong and Tang, Buzhou and Wu, Shaocong},
  year = {2020},
  journal = {Entropy},
  volume = {22},
  number = {10},
  doi = {10.3390/e22101162},
  issn = {1099-4300},
  url = {https://www.mdpi.com/1099-4300/22/10/1162},
  article-number = {1162},
  pubmedid = {33286931},
  abstract = {Time series prediction has been widely applied to the finance industry in applications such as stock market price and commodity price forecasting. Machine learning methods have been widely used in financial time series prediction in recent years. How to label financial time series data to determine the prediction accuracy of machine learning models and subsequently determine final investment returns is a hot topic. Existing labeling methods of financial time series mainly label data by comparing the current data with those of a short time period in the future. However, financial time series data are typically non-linear with obvious short-term randomness. Therefore, these labeling methods have not captured the continuous trend features of financial time series data, leading to a difference between their labeling results and real market trends. In this paper, a new labeling method called “continuous trend labeling” is proposed to address the above problem. In the feature preprocessing stage, this paper proposed a new method that can avoid the problem of look-ahead bias in traditional data standardization or normalization processes. Then, a detailed logical explanation was given, the definition of continuous trend labeling was proposed and also an automatic labeling algorithm was given to extract the continuous trend features of financial time series data. Experiments on the Shanghai Composite Index and Shenzhen Component Index and some stocks of China showed that our labeling method is a much better state-of-the-art labeling method in terms of classification accuracy and some other classification evaluation metrics. The results of the paper also proved that deep learning models such as LSTM and GRU are more suitable for dealing with the prediction of financial time series data.}
}

@article{zuboff2020surveillance,
  title = {Surveillance Capitalism},
  author = {Zuboff, Shoshana},
  year = {2020},
  journal = {Project Syndicate},
  url = {https://www.project-syndicate.org/magazine/surveillance-capitalism-exploiting-behavioral-data-by-shoshana-zuboff-2020-01}
}

@article{robeyns2020capability,
  title = {The Capability Approach},
  author = {Robeyns, Ingrid},
  year = {2020},
  journal = {Stanford Encyclopedia of Philosophy},
  publisher = {Stanford University},
  note = {First published 2011; substantive revision December 10, 2020},
  editor = {Zalta, Edward N.}
}

@article{cammarata2020thread,
  title = {Thread: Circuits},
  author = {Cammarata, Nick and Olah, Chris and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  year = {2020},
  journal = {Distill},
  note = {https://distill.pub/2020/circuits/}
}

@article{elhage2021mathematical,
  title = {A Mathematical Framework for Transformer Circuits},
  author = {Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  year = {2021},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2021/framework/index.html}
}

@article{olsson2022context,
  title = {In-context Learning and Induction Heads},
  author = {Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  year = {2022},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@article{elhage2022superposition,
  title = {Toy Models of Superposition},
  author = {Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
  year = {2022},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2022/toy_model/index.html}
}

@article{DWIVEDI2023102642,
  title = {Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
  author = {Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright},
  year = {2023},
  journal = {International Journal of Information Management},
  volume = {71},
  pages = {102642},
  doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102642},
  issn = {0268-4012},
  url = {https://www.sciencedirect.com/science/article/pii/S0268401223000233},
  keywords = {Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models},
  abstract = {Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.}
}

@article{bricken2023monosemanticity,
  title = {Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
  author = {Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
  year = {2023},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@article{lindsey2024sparsecrosscoders,
  title = {Sparse Crosscoders for Cross-Layer Features and Model Diffing},
  author = {Lindsey, Jack and Templeton, Adly and Marcus, Jonathan and Conerly, Thomas and Batson, Joshua and Olah, Christopher},
  year = {2024},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2024/crosscoders/index.html}
}

@article{templeton2024scaling,
  title = {Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
  author = {Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
  year = {2024},
  journal = {Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
}

@article{mckinsey2024techtrends,
  title = {McKinsey technology trends outlook 2024},
  author = {{McKinsey \& Company}},
  year = {2024},
  journal = {McKinsey Digital},
  url = {https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech},
  note = {Accessed on October 09, 2024}
}

@article{bussmann2024showing,
  title = {Showing SAE Latents Are Not Atomic Using Meta-SAEs},
  author = {Bart Bussmann and Michael Pearce and Patrick Leask and Joseph Bloom and Lee Sharkey and Neel Nanda},
  year = {2024},
  month = aug,
  url = {https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes},
  note = {Accessed: 2025-01-28}
}

@article{10440574,
  title = {Software Testing With Large Language Models: Survey, Landscape, and Vision},
  author = {Wang, Junjie and Huang, Yuchao and Chen, Chunyang and Liu, Zhe and Wang, Song and Wang, Qing},
  year = {2024},
  journal = {IEEE Transactions on Software Engineering},
  volume = {50},
  number = {4},
  pages = {911--936},
  doi = {10.1109/TSE.2024.3368208},
  keywords = {Software testing;Task analysis;Computational modeling;Codes;Software systems;Natural language processing;Reviews;Pre-trained large language model;software testing;LLM;GPT}
}

@article{scaling-book,
  title = {How to Scale Your Model},
  author = {Austin, Jacob and Douglas, Sholto and Frostig, Roy and Levskaya, Anselm and Chen, Charlie and Vikram, Sharad and Lebron, Federico and Choy, Peter and Ramasesh, Vinay and Webson, Albert and Pope, Reiner},
  year = {2025},
  publisher = {Google DeepMind},
  note = {Retrieved from https://jax-ml.github.io/scaling-book/},
  howpublished = {Online}
}

@book{Kant1785KANGFT,
  title = {Groundwork for the Metaphysics of Morals},
  author = {Immanuel Kant},
  year = {1785},
  publisher = {Oxford University Press},
  address = {New York},
  editor = {Thomas E. Hill and Arnulf Zweig}
}

@book{Edelstein1943EDETHO,
  title = {The Hippocratic Oath},
  author = {Ludwig Edelstein},
  year = {1943},
  publisher = {The Johns Hopkins press},
  address = {Baltimore,},
  editor = {}
}

@book{leibniz_selections_1951,
  title = {Leibniz Selections},
  author = {Leibniz, Gottfried Wilhelm},
  year = {1951},
  publisher = {Charles Scribner's Sons},
  address = {New York},
  pages = {606},
  editor = {Wiener, Philip P.}
}

@book{schouten1951tensor,
  title = {Tensor Analysis for Physicists},
  author = {Schouten, Jan Arnoldus},
  year = {1951},
  publisher = {Oxford University Press},
  address = {Oxford}
}

@book{wittgenstein1953philosophical,
  title = {Philosophical Investigations},
  author = {Wittgenstein, Ludwig},
  year = {1953},
  publisher = {Blackwell},
  address = {Oxford},
  isbn = {0631103201},
  note = {Translated from the German "Philosophische Untersuchungen"},
  translator = {Anscombe, G. E. M.}
}

@book{friedman1962capitalism,
  title = {Capitalism and Freedom},
  author = {Friedman, Milton and Friedman, Rose D.},
  year = {1962},
  publisher = {University of Chicago Press},
  address = {Chicago},
  pages = {202},
  isbn = {9780226264004}
}

@book{dreyfus1972what,
  title = {What Computers Can't Do: A Critique of Artificial Reason},
  author = {Dreyfus, Hubert L.},
  year = {1972},
  publisher = {Harper \& Row},
  address = {New York, NY},
  isbn = {978-0060906139},
  edition = {1st}
}

@book{deleuze1972anti,
  title = {Anti-Oedipus: Capitalism and Schizophrenia},
  author = {Deleuze, Gilles and Guattari, Félix},
  year = {1972},
  publisher = {Les Editions de Minuit}
}

@book{gadamer1977philosophical,
  title = {Philosophical Hermeneutics},
  author = {Gadamer, Hans-Georg},
  year = {1977},
  publisher = {University of California Press},
  address = {Berkeley},
  pages = {243},
  editor = {Linge, David E.}
}

@book{gadamer1980dialogue,
  title = {Dialogue and Dialectic: Eight Hermeneutical Studies on Plato},
  author = {Gadamer, Hans-Georg},
  year = {1980},
  publisher = {Yale University Press},
  address = {New Haven}
}

@book{10.7551/mitpress/5236.001.0001,
  title = {{Parallel Distributed Processing, Volume 1: Explorations in the Microstructure of Cognition: Foundations}},
  author = {Rumelhart, David E. and McClelland, James L. and PDP Research Group},
  year = {1986},
  month = {07},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/5236.001.0001},
  isbn = {9780262291408},
  url = {https://doi.org/10.7551/mitpress/5236.001.0001},
  abstract = {{What makes people smarter than computers? These volumes by a pioneering neurocomputing group suggest that the answer lies in the massively parallel architecture of the human mind. They describe a new theory of cognition called connectionism that is challenging the idea of symbolic computation that has traditionally been at the center of debate in theoretical discussions about the mind. The authors' theory assumes the mind is composed of a great number of elementary units connected in a neural network. Mental processes are interactions between these units which excite and inhibit each other in parallel rather than sequential operations. In this context, knowledge can no longer be thought of as stored in localized structures; instead, it consists of the connections between pairs of units that are distributed throughout the network. Volume 1 lays the foundations of this exciting theory of parallel distributed processing, while Volume 2 applies it to a number of specific issues in cognitive science and neuroscience, with chapters describing models of aspects of perception, memory, language, and thought.Bradford Books imprint}}
}

@book{10.7551/mitpress/4626.001.0001,
  title = {{Mind Design II: Philosophy, Psychology, and Artificial Intelligence}},
  author = {Haugeland, John},
  year = {1997},
  month = {03},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/4626.001.0001},
  isbn = {9780262275071},
  url = {https://doi.org/10.7551/mitpress/4626.001.0001},
  abstract = {{Mind design is the endeavor to understand mind (thinking, intellect) in terms of its design (how it is built, how it works). Unlike traditional empirical psychology, it is more oriented toward the "how" than the "what." An experiment in mind design is more likely to be an attempt to build something and make it work—as in artificial intelligence—than to observe or analyze what already exists. Mind design is psychology by reverse engineering.When Mind Design was first published in 1981, it became a classic in the then-nascent fields of cognitive science and AI. This second edition retains four landmark essays from the first, adding to them one earlier milestone (Turing's "Computing Machinery and Intelligence") and eleven more recent articles about connectionism, dynamical systems, and symbolic versus nonsymbolic models. The contributors are divided about evenly between philosophers and scientists. Yet all are "philosophical" in that they address fundamental issues and concepts; and all are "scientific" in that they are technically sophisticated and concerned with concrete empirical research.Contributors Rodney A. Brooks, Paul M. Churchland, Andy Clark, Daniel C. Dennett, Hubert L. Dreyfus, Jerry A. Fodor, Joseph Garon, John Haugeland, Marvin Minsky, Allen Newell, Zenon W. Pylyshyn, William Ramsey, Jay F. Rosenberg, David E. Rumelhart, John R. Searle, Herbert A. Simon, Paul Smolensky, Stephen Stich, A.M. Turing, Timothy van Gelder}}
}

@book{jackson_introduction_1998,
  title = {Introduction to Expert Systems},
  author = {Jackson, Peter},
  year = {1998},
  publisher = {Addison Wesley},
  address = {Harlow, England},
  series = {International computer science series},
  pages = {542},
  isbn = {978-0-201-87686-4},
  edition = {3}
}

@book{chomsky1999profit,
  title = {Profit Over People: Neoliberalism and Global Order},
  author = {Chomsky, Noam},
  year = {1999},
  publisher = {Seven Stories Press},
  address = {New York},
  isbn = {1-888363-82-7},
  price = {US\$15.95}
}

@book{rawls1999theory,
  title = {A Theory of Justice},
  author = {Rawls, John},
  year = {1999},
  publisher = {Belknap Press of Harvard University Press},
  address = {Cambridge, Massachusetts},
  edition = {Revised}
}

@book{aristotle_nicomachean_ethics,
  title = {Nicomachean Ethics},
  author = {Aristotle},
  year = {2009},
  publisher = {Oxford University Press},
  address = {Oxford},
  series = {Oxford World's Classics},
  isbn = {978-0199213610},
  translator = {Ross, W. D.},
  editor = {Brown, Lesley}
}

@book{mcconnell2014applications,
  title = {Applications of Tensor Analysis},
  author = {McConnell, A.J.},
  year = {2014},
  publisher = {Dover Publications},
  isbn = {9780486145020},
  url = {https://books.google.ca/books?id=ZCP0AwAAQBAJ}
}

@book{noble2018algorithms,
  title = {Algorithms of Oppression: How Search Engines Reinforce Racism},
  author = {Noble, Safiya Umoja},
  year = {2018},
  publisher = {New York University Press},
  address = {New York},
  pages = {229},
  isbn = {9781479837243}
}

@book{zuboff2019age,
  title = {The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power},
  author = {Zuboff, Shoshana},
  year = {2019},
  publisher = {PublicAffairs},
  address = {New York, NY},
  isbn = {9781781256855}
}

@book{couldry2019costs,
  title = {The Costs of Connection: How Data Is Colonizing Human Life and Appropriating It for Capitalism},
  author = {Couldry, Nick and Mejias, Ulises A.},
  year = {2019},
  publisher = {Stanford University Press},
  address = {Stanford, CA},
  isbn = {978-1-5036-0366-0},
  url = {https://www.sup.org/books/sociology/costs-connection}
}

@book{atlasofai,
  title = {The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence},
  author = {Kate Crawford},
  year = {2021},
  publisher = {Yale University Press},
  isbn = {9780300209570},
  url = {http://www.jstor.org/stable/j.ctv1ghv45t},
  urldate = {2024-10-09},
  abstract = {The hidden costs of artificial intelligence, from natural resources and labor to privacy and freedom What happens when artificial intelligence saturates political life and depletes the planet? How is AI shaping our understanding of ourselves and our societies? In this book Kate Crawford reveals how this planetary network is fueling a shift toward undemocratic governance and increased inequality. Drawing on more than a decade of research, award-winning science, and technology, Crawford reveals how AI is a technology of extraction: from the energy and minerals needed to build and sustain its infrastructure, to the exploited workers behind "automated" services, to the data AI collects from us. Rather than taking a narrow focus on code and algorithms, Crawford offers us a political and a material perspective on what it takes to make artificial intelligence and where it goes wrong. While technical systems present a veneer of objectivity, they are always systems of power. This is an urgent account of what is at stake as technology companies use artificial intelligence to reshape the world.}
}

@incollection{dreyfus2008why,
  title = {Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian},
  author = {Dreyfus, Hubert L.},
  year = {2008},
  booktitle = {The Mechanical Mind in History},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  pages = {331--362}
}

@inproceedings{novikoff1962convergence,
  title = {On Convergence Proofs for Perceptrons},
  author = {Albert B. J. Novikoff},
  year = {1962},
  booktitle = {Proceedings of the Symposium on the Mathematical Theory of Automata},
  publisher = {Polytechnic Institute of Brooklyn},
  address = {New York, NY, USA},
  volume = {12},
  pages = {615--622},
  url = {https://apps.dtic.mil/sti/tr/pdf/AD0298258.pdf}
}

@inproceedings{AlanKay1972,
  title = {A Personal Computer for Children of All Ages},
  author = {Kay, Alan C.},
  year = {2011},
  booktitle = {Proceedings of the ACM Annual Conference - Volume 1},
  location = {Boston, Massachusetts, USA},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {ACM '72},
  doi = {10.1145/800193.1971922},
  isbn = {9781450374910},
  url = {https://doi.org/10.1145/800193.1971922},
  abstract = {This note speculates about the emergence of personal, portable information manipulators and their effects when used by both children and adults. Although it should be read as science fiction, current trends in miniaturization and price reduction almost guarantee that many of the notions discussed will actually happen in the near future.},
  articleno = {1}
}

@inproceedings{mikolov-etal-2013-linguistic,
  title = {Linguistic Regularities in Continuous Space Word Representations},
  author = {Mikolov, Tomas  and Yih, Wen-tau  and Zweig, Geoffrey},
  year = {2013},
  month = jun,
  booktitle = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  publisher = {Association for Computational Linguistics},
  address = {Atlanta, Georgia},
  pages = {746--751},
  url = {https://aclanthology.org/N13-1090},
  editor = {Vanderwende, Lucy  and Daum{\'e} III, Hal  and Kirchhoff, Katrin}
}

@inproceedings{ribeiro2016lime,
  title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year = {2016},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  publisher = {ACM},
  pages = {1135--1144},
  doi = {10.1145/2939672.2939778}
}

@inproceedings{280922,
  title = {Orca: A Distributed Serving System for {Transformer-Based} Generative Models},
  author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
  year = {2022},
  month = jul,
  booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
  publisher = {USENIX Association},
  address = {Carlsbad, CA},
  pages = {521--538},
  isbn = {978-1-939133-28-1},
  url = {https://www.usenix.org/conference/osdi22/presentation/yu}
}

@inproceedings{kwon2023efficient,
  title = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author = {Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  year = {2023},
  booktitle = {Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles}
}

@misc{PEAct1990,
  title = {Professional Engineers Act, R.S.O. 1990, c. P.28},
  author = {{Government of Ontario}},
  year = {1990},
  publisher = {Government of Ontario},
  note = {Last amendment: 2024, c. 2, Sched. 1, s. 20}
}

@misc{mikolov2013efficientestimationwordrepresentations,
  title = {Efficient Estimation of Word Representations in Vector Space},
  author = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year = {2013},
  eprint = {1301.3781},
  url = {https://arxiv.org/abs/1301.3781},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{bartlett2014extended3dimensionalbordismtheory,
  title = {Extended 3-dimensional bordism as the theory of modular objects},
  author = {Bruce Bartlett and Christopher L. Douglas and Christopher J. Schommer-Pries and Jamie Vicary},
  year = {2014},
  eprint = {1411.0945},
  url = {https://arxiv.org/abs/1411.0945},
  archiveprefix = {arXiv},
  primaryclass = {math.GT}
}

@misc{lenc2015understandingimagerepresentationsmeasuring,
  title = {Understanding image representations by measuring their equivariance and equivalence},
  author = {Karel Lenc and Andrea Vedaldi},
  year = {2015},
  eprint = {1411.5908},
  url = {https://arxiv.org/abs/1411.5908},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV}
}

@misc{hinton2015distillingknowledgeneuralnetwork,
  title = {Distilling the Knowledge in a Neural Network},
  author = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
  year = {2015},
  eprint = {1503.02531},
  url = {https://arxiv.org/abs/1503.02531},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML}
}

@misc{srivastava2015highwaynetworks,
  title = {Highway Networks},
  author = {Rupesh Kumar Srivastava and Klaus Greff and Jürgen Schmidhuber},
  year = {2015},
  eprint = {1505.00387},
  url = {https://arxiv.org/abs/1505.00387},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{he2015deepresiduallearningimage,
  title = {Deep Residual Learning for Image Recognition},
  author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year = {2015},
  eprint = {1512.03385},
  url = {https://arxiv.org/abs/1512.03385},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV}
}

@misc{bahdanau2016neuralmachinetranslationjointly,
  title = {Neural Machine Translation by Jointly Learning to Align and Translate},
  author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  year = {2016},
  eprint = {1409.0473},
  url = {https://arxiv.org/abs/1409.0473},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{dauphin2017languagemodelinggatedconvolutional,
  title = {Language Modeling with Gated Convolutional Networks},
  author = {Yann N. Dauphin and Angela Fan and Michael Auli and David Grangier},
  year = {2017},
  eprint = {1612.08083},
  url = {https://arxiv.org/abs/1612.08083},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{raghu2017svccasingularvectorcanonical,
  title = {SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability},
  author = {Maithra Raghu and Justin Gilmer and Jason Yosinski and Jascha Sohl-Dickstein},
  year = {2017},
  eprint = {1706.05806},
  url = {https://arxiv.org/abs/1706.05806},
  archiveprefix = {arXiv},
  primaryclass = {stat.ML}
}

@misc{ramachandran2017searchingactivationfunctions,
  title = {Searching for Activation Functions},
  author = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  year = {2017},
  eprint = {1710.05941},
  url = {https://arxiv.org/abs/1710.05941},
  archiveprefix = {arXiv},
  primaryclass = {cs.NE}
}

@misc{silver2017masteringchessshogiselfplay,
  title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
  author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
  year = {2017},
  eprint = {1712.01815},
  url = {https://arxiv.org/abs/1712.01815},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{jacob2017quantizationtrainingneuralnetworks,
  title = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  author = {Benoit Jacob and Skirmantas Kligys and Bo Chen and Menglong Zhu and Matthew Tang and Andrew Howard and Hartwig Adam and Dmitry Kalenichenko},
  year = {2017},
  eprint = {1712.05877},
  url = {https://arxiv.org/abs/1712.05877},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{stern2018blockwiseparalleldecodingdeep,
  title = {Blockwise Parallel Decoding for Deep Autoregressive Models},
  author = {Mitchell Stern and Noam Shazeer and Jakob Uszkoreit},
  year = {2018},
  eprint = {1811.03115},
  url = {https://arxiv.org/abs/1811.03115},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{erichson2019jumpreluretrofitdefensestrategy,
  title = {JumpReLU: A Retrofit Defense Strategy for Adversarial Attacks},
  author = {N. Benjamin Erichson and Zhewei Yao and Michael W. Mahoney},
  year = {2019},
  eprint = {1904.03750},
  url = {https://arxiv.org/abs/1904.03750},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@misc{zhang2019rootmeansquarelayer,
  title = {Root Mean Square Layer Normalization},
  author = {Biao Zhang and Rico Sennrich},
  year = {2019},
  eprint = {1910.07467},
  url = {https://arxiv.org/abs/1910.07467},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{rajbhandari2020zeromemoryoptimizationstraining,
  title = {ZeRO: Memory Optimizations Toward Training Trillion Parameter Models},
  author = {Samyam Rajbhandari and Jeff Rasley and Olatunji Ruwase and Yuxiong He},
  year = {2020},
  eprint = {1910.02054},
  url = {https://arxiv.org/abs/1910.02054},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{kaplan2020scalinglawsneurallanguage,
  title = {Scaling Laws for Neural Language Models},
  author = {Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year = {2020},
  eprint = {2001.08361},
  url = {https://arxiv.org/abs/2001.08361},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{shazeer2020gluvariantsimprovetransformer,
  title = {GLU Variants Improve Transformer},
  author = {Noam Shazeer},
  year = {2020},
  eprint = {2002.05202},
  url = {https://arxiv.org/abs/2002.05202},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{brown2020languagemodelsfewshotlearners,
  title = {Language Models are Few-Shot Learners},
  author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year = {2020},
  eprint = {2005.14165},
  url = {https://arxiv.org/abs/2005.14165},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
  title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year = {2021},
  eprint = {2005.11401},
  url = {https://arxiv.org/abs/2005.11401},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{tan2021efficientnetv2smallermodelsfaster,
  title = {EfficientNetV2: Smaller Models and Faster Training},
  author = {Mingxing Tan and Quoc V. Le},
  year = {2021},
  eprint = {2104.00298},
  url = {https://arxiv.org/abs/2104.00298},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV}
}

@misc{tay2022efficienttransformerssurvey,
  title = {Efficient Transformers: A Survey},
  author = {Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
  year = {2022},
  eprint = {2009.06732},
  url = {https://arxiv.org/abs/2009.06732},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{wei2022finetunedlanguagemodelszeroshot,
  title = {Finetuned Language Models Are Zero-Shot Learners},
  author = {Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  year = {2022},
  eprint = {2109.01652},
  url = {https://arxiv.org/abs/2109.01652},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{power2022grokkinggeneralizationoverfittingsmall,
  title = {Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets},
  author = {Alethea Power and Yuri Burda and Harri Edwards and Igor Babuschkin and Vedant Misra},
  year = {2022},
  eprint = {2201.02177},
  url = {https://arxiv.org/abs/2201.02177},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{hao2022languagemodelsgeneralpurposeinterfaces,
  title = {Language Models are General-Purpose Interfaces},
  author = {Yaru Hao and Haoyu Song and Li Dong and Shaohan Huang and Zewen Chi and Wenhui Wang and Shuming Ma and Furu Wei},
  year = {2022},
  eprint = {2206.06336},
  url = {https://arxiv.org/abs/2206.06336},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{wei2022emergentabilitieslargelanguage,
  title = {Emergent Abilities of Large Language Models},
  author = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  year = {2022},
  eprint = {2206.07682},
  url = {https://arxiv.org/abs/2206.07682},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{abdelkhalik2022demystifyingnvidiaamperearchitecture,
  title = {Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis},
  author = {Hamdy Abdelkhalik and Yehia Arafa and Nandakishore Santhi and Abdel-Hameed Badawy},
  year = {2022},
  eprint = {2208.11174},
  url = {https://arxiv.org/abs/2208.11174},
  archiveprefix = {arXiv},
  primaryclass = {cs.AR}
}

@misc{keles2022computationalcomplexityselfattention,
  title = {On The Computational Complexity of Self-Attention},
  author = {Feyza Duman Keles and Pruthuvi Mahesakya Wijewardena and Chinmay Hegde},
  year = {2022},
  eprint = {2209.04881},
  url = {https://arxiv.org/abs/2209.04881},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{croft2023llm,
  title = {LLM Visualization},
  author = {Croft, Benjamin},
  year = {2023},
  note = {Accessed: 2023-06-28},
  howpublished = {\url{https://bbycroft.net/llm}}
}

@misc{nanda2023concrete,
  title = {Concrete Steps to Get Started in Transformer Mechanistic Interpretability},
  author = {Neel Nanda},
  year = {2023},
  note = {Blog post},
  howpublished = {\url{https://www.neelnanda.io/mechanistic-interpretability/getting-started}}
}

@misc{saxena2023prompt,
  title = {Prompt Lookup Decoding},
  author = {Apoorv Saxena},
  year = {2023},
  month = nov,
  url = {https://github.com/apoorvumang/prompt-lookup-decoding/}
}

@misc{vaswani2023attentionneed,
  title = {Attention Is All You Need},
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year = {2023},
  eprint = {1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{su2023roformerenhancedtransformerrotary,
  title = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author = {Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
  year = {2023},
  eprint = {2104.09864},
  url = {https://arxiv.org/abs/2104.09864},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year = {2023},
  eprint = {2201.11903},
  url = {https://arxiv.org/abs/2201.11903},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{xu2023multimodallearningtransformerssurvey,
  title = {Multimodal Learning with Transformers: A Survey},
  author = {Peng Xu and Xiatian Zhu and David A. Clifton},
  year = {2023},
  eprint = {2206.06488},
  url = {https://arxiv.org/abs/2206.06488},
  archiveprefix = {arXiv},
  primaryclass = {cs.CV}
}

@misc{frantar2023gptqaccurateposttrainingquantization,
  title = {GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author = {Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  year = {2023},
  eprint = {2210.17323},
  url = {https://arxiv.org/abs/2210.17323},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{leviathan2023fastinferencetransformersspeculative,
  title = {Fast Inference from Transformers via Speculative Decoding},
  author = {Yaniv Leviathan and Matan Kalman and Yossi Matias},
  year = {2023},
  eprint = {2211.17192},
  url = {https://arxiv.org/abs/2211.17192},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{nanda2023progressmeasuresgrokkingmechanistic,
  title = {Progress measures for grokking via mechanistic interpretability},
  author = {Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
  year = {2023},
  eprint = {2301.05217},
  url = {https://arxiv.org/abs/2301.05217},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{chen2023acceleratinglargelanguagemodel,
  title = {Accelerating Large Language Model Decoding with Speculative Sampling},
  author = {Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
  year = {2023},
  eprint = {2302.01318},
  url = {https://arxiv.org/abs/2302.01318},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{viégas2023modelusermodelexploring,
  title = {The System Model and the User Model: Exploring AI Dashboard Design},
  author = {Fernanda Viégas and Martin Wattenberg},
  year = {2023},
  eprint = {2305.02469},
  url = {https://arxiv.org/abs/2305.02469},
  archiveprefix = {arXiv},
  primaryclass = {cs.HC}
}

@misc{ainslie2023gqatraininggeneralizedmultiquery,
  title = {GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author = {Joshua Ainslie and James Lee-Thorp and Michiel de Jong and Yury Zemlyanskiy and Federico Lebrón and Sumit Sanghai},
  year = {2023},
  eprint = {2305.13245},
  url = {https://arxiv.org/abs/2305.13245},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{liu2023scissorhandsexploitingpersistenceimportance,
  title = {Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time},
  author = {Zichang Liu and Aditya Desai and Fangshuo Liao and Weitao Wang and Victor Xie and Zhaozhuo Xu and Anastasios Kyrillidis and Anshumali Shrivastava},
  year = {2023},
  eprint = {2305.17118},
  url = {https://arxiv.org/abs/2305.17118},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{lew2023sequentialmontecarlosteering,
  title = {Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs},
  author = {Alexander K. Lew and Tan Zhi-Xuan and Gabriel Grand and Vikash K. Mansinghka},
  year = {2023},
  eprint = {2306.03081},
  url = {https://arxiv.org/abs/2306.03081},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{zhang2023h2oheavyhitteroracleefficient,
  title = {H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models},
  author = {Zhenyu Zhang and Ying Sheng and Tianyi Zhou and Tianlong Chen and Lianmin Zheng and Ruisi Cai and Zhao Song and Yuandong Tian and Christopher Ré and Clark Barrett and Zhangyang Wang and Beidi Chen},
  year = {2023},
  eprint = {2306.14048},
  url = {https://arxiv.org/abs/2306.14048},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{willard2023efficientguidedgenerationlarge,
  title = {Efficient Guided Generation for Large Language Models},
  author = {Brandon T. Willard and Rémi Louf},
  year = {2023},
  eprint = {2307.09702},
  url = {https://arxiv.org/abs/2307.09702},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{peng2023yarnefficientcontextwindow,
  title = {YaRN: Efficient Context Window Extension of Large Language Models},
  author = {Bowen Peng and Jeffrey Quesnelle and Honglu Fan and Enrico Shippole},
  year = {2023},
  eprint = {2309.00071},
  url = {https://arxiv.org/abs/2309.00071},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{nijkamp2023xgen7btechnicalreport,
  title = {XGen-7B Technical Report},
  author = {Erik Nijkamp and Tian Xie and Hiroaki Hayashi and Bo Pang and Congying Xia and Chen Xing and Jesse Vig and Semih Yavuz and Philippe Laban and Ben Krause and Senthil Purushwalkam and Tong Niu and Wojciech Kryściński and Lidiya Murakhovs'ka and Prafulla Kumar Choubey and Alex Fabbri and Ye Liu and Rui Meng and Lifu Tu and Meghana Bhat and Chien-Sheng Wu and Silvio Savarese and Yingbo Zhou and Shafiq Joty and Caiming Xiong},
  year = {2023},
  eprint = {2309.03450},
  url = {https://arxiv.org/abs/2309.03450},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{dhuliawala2023chainofverificationreduceshallucinationlarge,
  title = {Chain-of-Verification Reduces Hallucination in Large Language Models},
  author = {Shehzaad Dhuliawala and Mojtaba Komeili and Jing Xu and Roberta Raileanu and Xian Li and Asli Celikyilmaz and Jason Weston},
  year = {2023},
  eprint = {2309.11495},
  url = {https://arxiv.org/abs/2309.11495},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{liu2023ringattentionblockwisetransformers,
  title = {Ring Attention with Blockwise Transformers for Near-Infinite Context},
  author = {Hao Liu and Matei Zaharia and Pieter Abbeel},
  year = {2023},
  eprint = {2310.01889},
  url = {https://arxiv.org/abs/2310.01889},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{huang2023surveyhallucinationlargelanguage,
  title = {A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
  author = {Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
  year = {2023},
  eprint = {2311.05232},
  url = {https://arxiv.org/abs/2311.05232},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{borzunov2023distributedinferencefinetuninglarge,
  title = {Distributed Inference and Fine-tuning of Large Language Models Over The Internet},
  author = {Alexander Borzunov and Max Ryabinin and Artem Chumachenko and Dmitry Baranchuk and Tim Dettmers and Younes Belkada and Pavel Samygin and Colin Raffel},
  year = {2023},
  eprint = {2312.08361},
  url = {https://arxiv.org/abs/2312.08361},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{tao2024machineassisted,
  title = {Machine-Assisted Proofs},
  author = {Terence Tao},
  year = {2024},
  month = mar,
  note = {Notices of the American Mathematical Society},
  howpublished = {\url{https://terrytao.wordpress.com/wp-content/uploads/2024/03/machine-assisted-proof-notices.pdf}}
}

@misc{gartner2024multimodal,
  title = {Gartner Predicts 40 Percent of Generative AI Solutions Will Be Multimodal By 2027},
  author = {Gartner},
  year = {2024},
  month = {09},
  day = {09},
  note = {Press Release},
  howpublished = {\url{https://www.gartner.com/en/newsroom/press-releases/2024-09-09-gartner-predicts-40-percent-of-generative-ai-solutions-will-be-multimodal-by-2027}}
}

@misc{rbc2024global,
  title = {Global Insight 2025 Outlook: Canada},
  author = {Sunny Singh and Josh Nye},
  year = {2024},
  month = dec,
  note = {RBC Wealth Management. Accessed: 13 February 2025.},
  howpublished = {\url{https://www.rbcwealthmanagement.com/en-ca/insights/global-insight-2025-outlook-canada}}
}

@misc{turner2024steeringlanguagemodelsactivation,
  title = {Steering Language Models With Activation Engineering},
  author = {Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
  year = {2024},
  eprint = {2308.10248},
  url = {https://arxiv.org/abs/2308.10248},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{zheng2024lmsyschat1mlargescalerealworldllm,
  title = {LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset},
  author = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric P. Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
  year = {2024},
  eprint = {2309.11998},
  url = {https://arxiv.org/abs/2309.11998},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{xiao2024efficientstreaminglanguagemodels,
  title = {Efficient Streaming Language Models with Attention Sinks},
  author = {Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis},
  year = {2024},
  eprint = {2309.17453},
  url = {https://arxiv.org/abs/2309.17453},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{ge2024modeltellsdiscardadaptive,
  title = {Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs},
  author = {Suyu Ge and Yunan Zhang and Liyuan Liu and Minjia Zhang and Jiawei Han and Jianfeng Gao},
  year = {2024},
  eprint = {2310.01801},
  url = {https://arxiv.org/abs/2310.01801},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{liu2024scalinglawsropebasedextrapolation,
  title = {Scaling Laws of RoPE-based Extrapolation},
  author = {Xiaoran Liu and Hang Yan and Shuo Zhang and Chenxin An and Xipeng Qiu and Dahua Lin},
  year = {2024},
  eprint = {2310.05209},
  url = {https://arxiv.org/abs/2310.05209},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{zhou2024distillspecimprovingspeculativedecoding,
  title = {DistillSpec: Improving Speculative Decoding via Knowledge Distillation},
  author = {Yongchao Zhou and Kaifeng Lyu and Ankit Singh Rawat and Aditya Krishna Menon and Afshin Rostamizadeh and Sanjiv Kumar and Jean-François Kagy and Rishabh Agarwal},
  year = {2024},
  eprint = {2310.08461},
  url = {https://arxiv.org/abs/2310.08461},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{gu2024mambalineartimesequencemodeling,
  title = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author = {Albert Gu and Tri Dao},
  year = {2024},
  eprint = {2312.00752},
  url = {https://arxiv.org/abs/2312.00752},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{panickssery2024steeringllama2contrastive,
  title = {Steering Llama 2 via Contrastive Activation Addition},
  author = {Nina Panickssery and Nick Gabrieli and Julian Schulz and Meg Tong and Evan Hubinger and Alexander Matt Turner},
  year = {2024},
  eprint = {2312.06681},
  url = {https://arxiv.org/abs/2312.06681},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{zheng2024sglangefficientexecutionstructured,
  title = {SGLang: Efficient Execution of Structured Language Model Programs},
  author = {Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Chuyue Sun and Jeff Huang and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
  year = {2024},
  eprint = {2312.07104},
  url = {https://arxiv.org/abs/2312.07104},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{sheng2024fairnessservinglargelanguage,
  title = {Fairness in Serving Large Language Models},
  author = {Ying Sheng and Shiyi Cao and Dacheng Li and Banghua Zhu and Zhuohan Li and Danyang Zhuo and Joseph E. Gonzalez and Ion Stoica},
  year = {2024},
  eprint = {2401.00588},
  url = {https://arxiv.org/abs/2401.00588},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{holmes2024deepspeedfastgenhighthroughputtextgeneration,
  title = {DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference},
  author = {Connor Holmes and Masahiro Tanaka and Michael Wyatt and Ammar Ahmad Awan and Jeff Rasley and Samyam Rajbhandari and Reza Yazdani Aminabadi and Heyang Qin and Arash Bakhtiari and Lev Kurilenko and Yuxiong He},
  year = {2024},
  eprint = {2401.08671},
  url = {https://arxiv.org/abs/2401.08671},
  archiveprefix = {arXiv},
  primaryclass = {cs.PF}
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
  title = {DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
  year = {2024},
  eprint = {2402.03300},
  url = {https://arxiv.org/abs/2402.03300},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{zelikman2024quietstarlanguagemodelsteach,
  title = {Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking},
  author = {Eric Zelikman and Georges Harik and Yijia Shao and Varuna Jayasiri and Nick Haber and Noah D. Goodman},
  year = {2024},
  eprint = {2403.09629},
  url = {https://arxiv.org/abs/2403.09629},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{gholami2024aimemorywall,
  title = {AI and Memory Wall},
  author = {Amir Gholami and Zhewei Yao and Sehoon Kim and Coleman Hooper and Michael W. Mahoney and Kurt Keutzer},
  year = {2024},
  eprint = {2403.14123},
  url = {https://arxiv.org/abs/2403.14123},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{béchard2024reducinghallucinationstructuredoutputs,
  title = {Reducing hallucination in structured outputs via Retrieval-Augmented Generation},
  author = {Patrice Béchard and Orlando Marquez Ayala},
  year = {2024},
  eprint = {2404.08189},
  url = {https://arxiv.org/abs/2404.08189},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{pozdniakov2024largelanguagemodelsmeet,
  title = {Large Language Models Meet User Interfaces: The Case of Provisioning Feedback},
  author = {Stanislav Pozdniakov and Jonathan Brazil and Solmaz Abdi and Aneesha Bakharia and Shazia Sadiq and Dragan Gasevic and Paul Denny and Hassan Khosravi},
  year = {2024},
  eprint = {2404.11072},
  url = {https://arxiv.org/abs/2404.11072},
  archiveprefix = {arXiv},
  primaryclass = {cs.HC}
}

@misc{li2024snapkvllmknowslooking,
  title = {SnapKV: LLM Knows What You are Looking for Before Generation},
  author = {Yuhong Li and Yingbing Huang and Bowen Yang and Bharat Venkitesh and Acyr Locatelli and Hanchen Ye and Tianle Cai and Patrick Lewis and Deming Chen},
  year = {2024},
  eprint = {2404.14469},
  url = {https://arxiv.org/abs/2404.14469},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{rajamanoharan2024improvingdictionarylearninggated,
  title = {Improving Dictionary Learning with Gated Sparse Autoencoders},
  author = {Senthooran Rajamanoharan and Arthur Conmy and Lewis Smith and Tom Lieberum and Vikrant Varma and János Kramár and Rohin Shah and Neel Nanda},
  year = {2024},
  eprint = {2404.16014},
  url = {https://arxiv.org/abs/2404.16014},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{wertheimer2024acceleratingproductionllmscombined,
  title = {Accelerating Production LLMs with Combined Token/Embedding Speculators},
  author = {Davis Wertheimer and Joshua Rosenkranz and Thomas Parnell and Sahil Suneja and Pavithra Ranganathan and Raghu Ganti and Mudhakar Srivatsa},
  year = {2024},
  eprint = {2404.19124},
  url = {https://arxiv.org/abs/2404.19124},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{gloeckle2024betterfasterlarge,
  title = {Better & Faster Large Language Models via Multi-token Prediction},
  author = {Fabian Gloeckle and Badr Youbi Idrissi and Baptiste Rozière and David Lopez-Paz and Gabriel Synnaeve},
  year = {2024},
  eprint = {2404.19737},
  url = {https://arxiv.org/abs/2404.19737},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{mamou2024dynamicspeculationlookaheadaccelerates,
  title = {Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large Language Models},
  author = {Jonathan Mamou and Oren Pereg and Daniel Korat and Moshe Berchansky and Nadav Timor and Moshe Wasserblat and Roy Schwartz},
  year = {2024},
  eprint = {2405.04304},
  url = {https://arxiv.org/abs/2405.04304},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{huh2024platonicrepresentationhypothesis,
  title = {The Platonic Representation Hypothesis},
  author = {Minyoung Huh and Brian Cheung and Tongzhou Wang and Phillip Isola},
  year = {2024},
  eprint = {2405.07987},
  url = {https://arxiv.org/abs/2405.07987},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{dao2024transformersssmsgeneralizedmodels,
  title = {Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
  author = {Tri Dao and Albert Gu},
  year = {2024},
  eprint = {2405.21060},
  url = {https://arxiv.org/abs/2405.21060},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{blakeney2024doesdatasparkjoy,
  title = {Does your data spark joy? Performance gains from domain upsampling at the end of training},
  author = {Cody Blakeney and Mansheej Paul and Brett W. Larsen and Sean Owen and Jonathan Frankle},
  year = {2024},
  eprint = {2406.03476},
  url = {https://arxiv.org/abs/2406.03476},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{gorton2024missingcurvedetectorsinceptionv1,
  title = {The Missing Curve Detectors of InceptionV1: Applying Sparse Autoencoders to InceptionV1 Early Vision},
  author = {Liv Gorton},
  year = {2024},
  eprint = {2406.03662},
  url = {https://arxiv.org/abs/2406.03662},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{liu2024optimizingspeculativedecodingserving,
  title = {Optimizing Speculative Decoding for Serving Large Language Models Using Goodput},
  author = {Xiaoxuan Liu and Cade Daniel and Langxiang Hu and Woosuk Kwon and Zhuohan Li and Xiangxi Mo and Alvin Cheung and Zhijie Deng and Ion Stoica and Hao Zhang},
  year = {2024},
  eprint = {2406.14066},
  url = {https://arxiv.org/abs/2406.14066},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{li2024eagle2fasterinferencelanguage,
  title = {EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees},
  author = {Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang},
  year = {2024},
  eprint = {2406.16858},
  url = {https://arxiv.org/abs/2406.16858},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{qin2024mooncakekvcachecentricdisaggregatedarchitecture,
  title = {Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving},
  author = {Ruoyu Qin and Zheming Li and Weiran He and Mingxing Zhang and Yongwei Wu and Weimin Zheng and Xinran Xu},
  year = {2024},
  eprint = {2407.00079},
  url = {https://arxiv.org/abs/2407.00079},
  archiveprefix = {arXiv},
  primaryclass = {cs.DC}
}

@misc{rajamanoharan2024jumpingaheadimprovingreconstruction,
  title = {Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders},
  author = {Senthooran Rajamanoharan and Tom Lieberum and Nicolas Sonnerat and Arthur Conmy and Vikrant Varma and János Kramár and Neel Nanda},
  year = {2024},
  eprint = {2407.14435},
  url = {https://arxiv.org/abs/2407.14435},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{tang2024razorattentionefficientkvcache,
  title = {RazorAttention: Efficient KV Cache Compression Through Retrieval Heads},
  author = {Hanlin Tang and Yang Lin and Jing Lin and Qingsen Han and Shikuan Hong and Yiwu Yao and Gongyi Wang},
  year = {2024},
  eprint = {2407.15891},
  url = {https://arxiv.org/abs/2407.15891},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{grattafiori2024llama3herdmodels,
  title = {The Llama 3 Herd of Models},
  author = {Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
  year = {2024},
  eprint = {2407.21783},
  url = {https://arxiv.org/abs/2407.21783},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{hänni2024mathematicalmodelscomputationsuperposition,
  title = {Mathematical Models of Computation in Superposition},
  author = {Kaarel Hänni and Jake Mendel and Dmitry Vaintrob and Lawrence Chan},
  year = {2024},
  eprint = {2408.05451},
  url = {https://arxiv.org/abs/2408.05451},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{jambateam2024jamba15hybridtransformermambamodels,
  title = {Jamba-1.5: Hybrid Transformer-Mamba Models at Scale},
  author = {Jamba Team and Barak Lenz and Alan Arazi and Amir Bergman and Avshalom Manevich and Barak Peleg and Ben Aviram and Chen Almagor and Clara Fridman and Dan Padnos and Daniel Gissin and Daniel Jannai and Dor Muhlgay and Dor Zimberg and Edden M Gerber and Elad Dolev and Eran Krakovsky and Erez Safahi and Erez Schwartz and Gal Cohen and Gal Shachaf and Haim Rozenblum and Hofit Bata and Ido Blass and Inbal Magar and Itay Dalmedigos and Jhonathan Osin and Julie Fadlon and Maria Rozman and Matan Danos and Michael Gokhman and Mor Zusman and Naama Gidron and Nir Ratner and Noam Gat and Noam Rozen and Oded Fried and Ohad Leshno and Omer Antverg and Omri Abend and Opher Lieber and Or Dagan and Orit Cohavi and Raz Alon and Ro'i Belson and Roi Cohen and Rom Gilad and Roman Glozman and Shahar Lev and Shaked Meirom and Tal Delbari and Tal Ness and Tomer Asida and Tom Ben Gal and Tom Braude and Uriya Pumerantz and Yehoshua Cohen and Yonatan Belinkov and Yuval Globerson and Yuval Peleg Levy and Yoav Shoham},
  year = {2024},
  eprint = {2408.12570},
  url = {https://arxiv.org/abs/2408.12570},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{bernstein2024modulardualitydeeplearning,
  title = {Modular Duality in Deep Learning},
  author = {Jeremy Bernstein and Laker Newhouse},
  year = {2024},
  eprint = {2410.21265},
  url = {https://arxiv.org/abs/2410.21265},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{marshall2024refusalllmsaffinefunction,
  title = {Refusal in LLMs is an Affine Function},
  author = {Thomas Marshall and Adam Scherlis and Nora Belrose},
  year = {2024},
  eprint = {2411.09003},
  url = {https://arxiv.org/abs/2411.09003},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{greenblatt2024alignmentfakinglargelanguage,
  title = {Alignment faking in large language models},
  author = {Ryan Greenblatt and Carson Denison and Benjamin Wright and Fabien Roger and Monte MacDiarmid and Sam Marks and Johannes Treutlein and Tim Belonax and Jack Chen and David Duvenaud and Akbir Khan and Julian Michael and Sören Mindermann and Ethan Perez and Linda Petrini and Jonathan Uesato and Jared Kaplan and Buck Shlegeris and Samuel R. Bowman and Evan Hubinger},
  year = {2024},
  eprint = {2412.14093},
  url = {https://arxiv.org/abs/2412.14093},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{CBV2025,
  title = {CBV \& CFA®: Complementary Designations to Advance Your Career},
  author = {{CBV Institute}},
  year = {2025},
  note = {Accessed: 2025-02-14},
  howpublished = {\url{https://cbvinstitute.com/events/cbv-cfa-complementary-designations-to-advance-your-career/}}
}

@misc{li2025eaglespeculativesamplingrequires,
  title = {EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty},
  author = {Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang},
  year = {2025},
  eprint = {2401.15077},
  url = {https://arxiv.org/abs/2401.15077},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{cai2025pyramidkvdynamickvcache,
  title = {PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling},
  author = {Zefan Cai and Yichi Zhang and Bofei Gao and Yuliang Liu and Yucheng Li and Tianyu Liu and Keming Lu and Wayne Xiong and Yue Dong and Junjie Hu and Wen Xiao},
  year = {2025},
  eprint = {2406.02069},
  url = {https://arxiv.org/abs/2406.02069},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{feng2025adakvoptimizingkvcache,
  title = {Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference},
  author = {Yuan Feng and Junlin Lv and Yukun Cao and Xike Xie and S. Kevin Zhou},
  year = {2025},
  eprint = {2407.11550},
  url = {https://arxiv.org/abs/2407.11550},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{shyam2025treeattentiontopologyawaredecoding,
  title = {Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters},
  author = {Vasudev Shyam and Jonathan Pilault and Emily Shepperd and Quentin Anthony and Beren Millidge},
  year = {2025},
  eprint = {2408.04093},
  url = {https://arxiv.org/abs/2408.04093},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{zhang2025learningharmonizedrepresentationsspeculative,
  title = {Learning Harmonized Representations for Speculative Sampling},
  author = {Lefan Zhang and Xiaodan Wang and Yanhua Huang and Ruiwen Xu},
  year = {2025},
  eprint = {2408.15766},
  url = {https://arxiv.org/abs/2408.15766},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{gao2025falconfasterparallelinference,
  title = {Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree},
  author = {Xiangxiang Gao and Weisheng Xie and Yiwei Xiang and Feng Ji},
  year = {2025},
  eprint = {2412.12639},
  url = {https://arxiv.org/abs/2412.12639},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
  title = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author = {DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
  year = {2025},
  eprint = {2501.12948},
  url = {https://arxiv.org/abs/2501.12948},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{ong2025toploclocalitysensitivehashing,
  title = {TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference},
  author = {Jack Min Ong and Matthew Di Ferrante and Aaron Pazdera and Ryan Garner and Sami Jaghouar and Manveer Basra and Max Ryabinin and Johannes Hagemann},
  year = {2025},
  eprint = {2501.16007},
  url = {https://arxiv.org/abs/2501.16007},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@misc{sharkey2025openproblemsmechanisticinterpretability,
  title = {Open Problems in Mechanistic Interpretability},
  author = {Lee Sharkey and Bilal Chughtai and Joshua Batson and Jack Lindsey and Jeff Wu and Lucius Bushnaq and Nicholas Goldowsky-Dill and Stefan Heimersheim and Alejandro Ortega and Joseph Bloom and Stella Biderman and Adria Garriga-Alonso and Arthur Conmy and Neel Nanda and Jessica Rumbelow and Martin Wattenberg and Nandi Schoots and Joseph Miller and Eric J. Michaud and Stephen Casper and Max Tegmark and William Saunders and David Bau and Eric Todd and Atticus Geiger and Mor Geva and Jesse Hoogland and Daniel Murfet and Tom McGrath},
  year = {2025},
  eprint = {2501.16496},
  url = {https://arxiv.org/abs/2501.16496},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{li2025eagle3scalinginferenceacceleration,
  title = {EAGLE-3: Scaling up Inference Acceleration of Large Language Models via Training-Time Test},
  author = {Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang},
  year = {2025},
  eprint = {2503.01840},
  url = {https://arxiv.org/abs/2503.01840},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{zhang2025jengaeffectivememorymanagement,
  title = {Jenga: Effective Memory Management for Serving LLM with Heterogeneity},
  author = {Chen Zhang and Kuntai Du and Shu Liu and Woosuk Kwon and Xiangxi Mo and Yufeng Wang and Xiaoxuan Liu and Kaichao You and Zhuohan Li and Mingsheng Long and Jidong Zhai and Joseph Gonzalez and Ion Stoica},
  year = {2025},
  eprint = {2503.18292},
  url = {https://arxiv.org/abs/2503.18292},
  archiveprefix = {arXiv},
  primaryclass = {cs.DC}
}

@misc{minder2025overcomingsparsityartifactscrosscoders,
  title = {Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning},
  author = {Julian Minder and Clément Dumas and Caden Juang and Bilal Chugtai and Neel Nanda},
  year = {2025},
  eprint = {2504.02922},
  url = {https://arxiv.org/abs/2504.02922},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{xu2025scalablechainthoughtselastic,
  title = {Scalable Chain of Thoughts via Elastic Reasoning},
  author = {Yuhui Xu and Hanze Dong and Lei Wang and Doyen Sahoo and Junnan Li and Caiming Xiong},
  year = {2025},
  eprint = {2505.05315},
  url = {https://arxiv.org/abs/2505.05315},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{morris2025languagemodelsmemorize,
  title = {How much do language models memorize?},
  author = {John X. Morris and Chawin Sitawarin and Chuan Guo and Narine Kokhlikyan and G. Edward Suh and Alexander M. Rush and Kamalika Chaudhuri and Saeed Mahloujifar},
  year = {2025},
  eprint = {2505.24832},
  url = {https://arxiv.org/abs/2505.24832},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@misc{shojaee2025illusionthinkingunderstandingstrengths,
  title = {The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity},
  author = {Parshin Shojaee and Iman Mirzadeh and Keivan Alizadeh and Maxwell Horton and Samy Bengio and Mehrdad Farajtabar},
  year = {2025},
  eprint = {2506.06941},
  url = {https://arxiv.org/abs/2506.06941},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@misc{sheshadri2025languagemodelsfakealignment,
  title = {Why Do Some Language Models Fake Alignment While Others Don't?},
  author = {Abhay Sheshadri and John Hughes and Julian Michael and Alex Mallen and Arun Jose and Janus and Fabien Roger},
  year = {2025},
  eprint = {2506.18032},
  url = {https://arxiv.org/abs/2506.18032},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{bogdan2025thoughtanchorsllmreasoning,
  title = {Thought Anchors: Which LLM Reasoning Steps Matter?},
  author = {Paul C. Bogdan and Uzay Macar and Neel Nanda and Arthur Conmy},
  year = {2025},
  eprint = {2506.19143},
  url = {https://arxiv.org/abs/2506.19143},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@misc{saxena2025utilitydrivenspeculativedecodingmixtureofexperts,
  title = {Utility-Driven Speculative Decoding for Mixture-of-Experts},
  author = {Anish Saxena and Po-An Tsai and Hritvik Taneja and Aamer Jaleel and Moinuddin Qureshi},
  year = {2025},
  eprint = {2506.20675},
  url = {https://arxiv.org/abs/2506.20675},
  archiveprefix = {arXiv},
  primaryclass = {cs.DC}
}

@misc{computerhistory_babbage,
  title = {The Engines},
  author = {{Computer History Museum}},
  year = {n.d.},
  publisher = {Computer History Museum},
  url = {https://www.computerhistory.org/babbage/engines/},
  note = {Retrieved December 23, 2024}
}

@misc{IBMModels,
  title = {IBM Models},
  author = {{Statistical Machine Translation}},
  year = {n.d.},
  publisher = {Statistical Machine Translation Survey},
  url = {http://www2.statmt.org/survey/Topic/IBMModels},
  note = {Retrieved December 24, 2024}
}

@online{sharkey2024feature,
  title = {Addressing Feature Suppression in {SAEs}},
  author = {Sharkey, Lee},
  year = {2024},
  url = {https://www.alignmentforum.org/posts/3JuSjTZyMzaSeTxKk/addressing-feature-suppression-in-saes},
  urldate = {2024-10-31},
  note = {Produced as part of the ML Alignment Theory Scholars Program - Winter 2023-24 Cohort},
  organization = {AI Alignment Forum}
}

@online{scotia2024,
  title = {Wealth Insights—Winter 2025},
  author = {{Scotia Wealth Management}},
  year = {2024},
  month = nov,
  day = {14},
  publisher = {Scotia Wealth Management},
  url = {https://enrichedthinking.scotiawealthmanagement.com/2024/11/14/wealth-insights-winter-2025/},
  note = {Accessed: February 14, 2025}
}

@software{yangbentoml2022,
  title = {{BentoML: The framework for building reliable, scalable and cost-efficient AI application}},
  author = {Yang, Chaoyu and Sheng Sean and Pham Aaron and  Zhao Shenyang and Lee Sauyon and Jiang Bo and Dong Fog and Guan Xipeng and Ming Frost},
  url = {https://github.com/bentoml/BentoML},
  license = {Apache-2.0}
}

@techreport{shortliffe1974mycin,
  title = {MYCIN: A Rule-Based Computer Program for Advising Physicians Regarding Antimicrobial Therapy Selection},
  author = {Shortliffe, Edward H.},
  year = {1974},
  address = {Stanford, CA},
  number = {STAN-CS-74-465},
  institution = {Stanford University},
  type = {Technical Report},
  school = {Computer Science Department}
}

@techreport{phipaguide2004,
  title = {A Guide to the Personal Health Information Protection Act},
  author = {{Information and Privacy Commissioner of Ontario}},
  year = {2004},
  institution = {Information and Privacy Commissioner of Ontario},
  type = {Technical Report}
}

@techreport{pipedaguide2024,
  title = {PIPEDA Requirements in Brief},
  author = {{Office of the Privacy Commissioner of Canada}},
  year = {2024},
  institution = {Office of the Privacy Commissioner of Canada},
  type = {Guidance Document}
}

@techreport{aida2024companion,
  title = {The Artificial Intelligence and Data Act (AIDA) - Companion Document},
  author = {{Innovation, Science and Economic Development Canada}},
  year = {2024},
  address = {Ottawa, ON},
  note = {Part of Bill C-27, the Digital Charter Implementation Act, 2022},
  institution = {Government of Canada},
  type = {Policy Document}
}
